(GeneticTrading) alex@alex-System-Product-Name:/mnt/windows/GeneticTrading$ python start_complete_system.py
INFO:__main__:ğŸš€ Starting Complete NQ Trading System
INFO:__main__:============================================================
INFO:__main__:ğŸš€ Starting TensorBoard...
INFO:__main__:âœ… TensorBoard started on http://0.0.0.0:6006
INFO:__main__:â³ Waiting for TensorBoard... (1/30)
INFO:__main__:âœ… TensorBoard is ready!
INFO:__main__:ğŸ§  Starting training process...
INFO:__main__:âœ… Training started
INFO:__main__:â³ Waiting for training to initialize...
[TRAINING] W0710 22:04:17.855000 28319 site-packages/torch/distributed/run.py:766]
[TRAINING] W0710 22:04:17.855000 28319 site-packages/torch/distributed/run.py:766] *****************************************
[TRAINING] W0710 22:04:17.855000 28319 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
[TRAINING] W0710 22:04:17.855000 28319 site-packages/torch/distributed/run.py:766] *****************************************
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ================================================================================
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ¯ Revolutionary NQ Futures Trading System
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ“Š Session started at 2025-07-10 22:04:20.090342
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ’» Process rank: 0
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ“ Log file: logs/trading_system_rank_0.log
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ================================================================================
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ MAIN           : ğŸš€ Revolutionary Trading System Started
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ MAIN           : NCCL_TIMEOUT = 1800000 ms
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ MAIN           : Using 100.0% of available data
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ MAIN           : Models directory: ./models
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ MAIN           : Training mode: adaptive
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ MAIN           : Device configuration: cuda:0
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ MAIN           : World size: 4, Local rank: 0
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Rank 0/4 starting on cuda:0 (has_cudf=True)
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Data loading parameters: max_rows=None, data_percentage=1.0
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : No row limit specified, using 1M row chunks for memory efficiency
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Parquet cache found; skipping preprocessing.
[TRAINING] alex-System-Product-Name:28353:28353 [0] NCCL INFO Bootstrap: Using wlp0s20f3:192.168.0.129<0>
[TRAINING] alex-System-Product-Name:28353:28353 [0] NCCL INFO cudaDriverVersion 12020
[TRAINING] alex-System-Product-Name:28353:28353 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
[TRAINING] alex-System-Product-Name:28353:28353 [0] NCCL INFO Comm config Blocking set to 1
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO NET/IB : No device found.
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO NET/IB : Using [RO]; OOB wlp0s20f3:192.168.0.129<0>
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO NET/Socket : Using [0]wlp0s20f3:192.168.0.129<0> [1]br-447583e7b32a:172.18.0.1<0> [2]br-81374c9c6e9c:172.19.0.1<0> [3]br-aaa630fe606a:172.20.0.1<0> [4]br-bc0f5ef31d4f:192.168.128.1<0>
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so.
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO Using network Socket
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO ncclCommInitRankConfig comm 0x6329636d67d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1000 commId 0x5a414978268db56c - Init START
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ================================================================================
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ¯ Revolutionary NQ Futures Trading System
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ“Š Session started at 2025-07-10 22:04:20.243788
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ’» Process rank: 1
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ“ Log file: logs/trading_system_rank_1.log
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ================================================================================
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Rank 1/4 starting on cuda:1 (has_cudf=True)
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Data loading parameters: max_rows=None, data_percentage=1.0
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : No row limit specified, using 1M row chunks for memory efficiency
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ================================================================================
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ¯ Revolutionary NQ Futures Trading System
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ“Š Session started at 2025-07-10 22:04:20.244531
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ’» Process rank: 3
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ“ Log file: logs/trading_system_rank_3.log
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ================================================================================
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Rank 3/4 starting on cuda:3 (has_cudf=True)
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Data loading parameters: max_rows=None, data_percentage=1.0
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : No row limit specified, using 1M row chunks for memory efficiency
[TRAINING] alex-System-Product-Name:28354:28354 [1] NCCL INFO cudaDriverVersion 12020
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ================================================================================
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ¯ Revolutionary NQ Futures Trading System
[TRAINING] alex-System-Product-Name:28356:28356 [3] NCCL INFO cudaDriverVersion 12020
[TRAINING] alex-System-Product-Name:28354:28354 [1] NCCL INFO Bootstrap: Using wlp0s20f3:192.168.0.129<0>
[TRAINING] alex-System-Product-Name:28354:28354 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ“Š Session started at 2025-07-10 22:04:20.250158
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ’» Process rank: 2
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ğŸ“ Log file: logs/trading_system_rank_2.log
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ SESSION        : ================================================================================
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Rank 2/4 starting on cuda:2 (has_cudf=True)
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Data loading parameters: max_rows=None, data_percentage=1.0
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : No row limit specified, using 1M row chunks for memory efficiency
[TRAINING] alex-System-Product-Name:28356:28356 [3] NCCL INFO Bootstrap: Using wlp0s20f3:192.168.0.129<0>
[TRAINING] alex-System-Product-Name:28356:28356 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
[TRAINING] alex-System-Product-Name:28354:28354 [1] NCCL INFO Comm config Blocking set to 1
[TRAINING] alex-System-Product-Name:28356:28356 [3] NCCL INFO Comm config Blocking set to 1
[TRAINING] alex-System-Product-Name:28355:28355 [2] NCCL INFO cudaDriverVersion 12020
[TRAINING] alex-System-Product-Name:28355:28355 [2] NCCL INFO Bootstrap: Using wlp0s20f3:192.168.0.129<0>
[TRAINING] alex-System-Product-Name:28355:28355 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
[TRAINING] alex-System-Product-Name:28355:28355 [2] NCCL INFO Comm config Blocking set to 1
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO NET/IB : No device found.
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO NET/IB : Using [RO]; OOB wlp0s20f3:192.168.0.129<0>
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO NET/Socket : Using [0]wlp0s20f3:192.168.0.129<0> [1]br-447583e7b32a:172.18.0.1<0> [2]br-81374c9c6e9c:172.19.0.1<0> [3]br-aaa630fe606a:172.20.0.1<0> [4]br-bc0f5ef31d4f:192.168.128.1<0>
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so.
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO Using network Socket
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO ncclCommInitRankConfig comm 0x55e74690efe0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 5000 commId 0x5a414978268db56c - Init START
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO NET/IB : No device found.
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO NET/IB : Using [RO]; OOB wlp0s20f3:192.168.0.129<0>
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO NET/Socket : Using [0]wlp0s20f3:192.168.0.129<0> [1]br-447583e7b32a:172.18.0.1<0> [2]br-81374c9c6e9c:172.19.0.1<0> [3]br-aaa630fe606a:172.20.0.1<0> [4]br-bc0f5ef31d4f:192.168.128.1<0>
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so.
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO Using network Socket
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO ncclCommInitRankConfig comm 0x5d0413d26f00 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId 9000 commId 0x5a414978268db56c - Init START
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO RAS client listening socket at 127.0.0.1<28028>
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO NET/IB : No device found.
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO NET/IB : Using [RO]; OOB wlp0s20f3:192.168.0.129<0>
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO NET/Socket : Using [0]wlp0s20f3:192.168.0.129<0> [1]br-447583e7b32a:172.18.0.1<0> [2]br-81374c9c6e9c:172.19.0.1<0> [3]br-aaa630fe606a:172.20.0.1<0> [4]br-bc0f5ef31d4f:192.168.128.1<0>
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so.
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO Using network Socket
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO ncclCommInitRankConfig comm 0x635b246730d0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8000 commId 0x5a414978268db56c - Init START
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO RAS client listening socket at 127.0.0.1<28028>
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO RAS client listening socket at 127.0.0.1<28028>
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO RAS client listening socket at 127.0.0.1<28028>
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO Bootstrap timings total 0.000257 (create 0.000011, send 0.000055, recv 0.000062, ring 0.000025, delay 0.000000)
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO Bootstrap timings total 0.018114 (create 0.000008, send 0.000044, recv 0.000014, ring 0.000022, delay 0.000000)
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO Bootstrap timings total 0.019237 (create 0.000014, send 0.000067, recv 0.019014, ring 0.000032, delay 0.000000)
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO Bootstrap timings total 0.094377 (create 0.000015, send 0.000068, recv 0.075203, ring 0.012787, delay 0.000000)
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO NVLS multicast support is not available on dev 2
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO NVLS multicast support is not available on dev 1
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO NVLS multicast support is not available on dev 0
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO NVLS multicast support is not available on dev 3
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO comm 0x55e74690efe0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO comm 0x635b246730d0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO comm 0x6329636d67d0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 3/-1/-1->1->-1 [2] 2/-1/-1->1->0 [3] 3/-1/-1->1->-1
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] -1/-1/-1->2->0 [2] 3/-1/-1->2->1 [3] -1/-1/-1->2->0
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO comm 0x5d0413d26f00 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO P2P Chunksize set to 131072
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO P2P Chunksize set to 131072
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO Channel 00/04 : 0 2 3 1
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO Channel 01/04 : 0 1 3 2
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO Channel 02/04 : 0 2 3 1
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO Channel 03/04 : 0 1 3 2
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 2/-1/-1->0->3 [2] 1/-1/-1->0->-1 [3] 2/-1/-1->0->3
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 0/-1/-1->3->1 [2] -1/-1/-1->3->2 [3] 0/-1/-1->3->1
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO P2P Chunksize set to 131072
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO P2P Chunksize set to 131072
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 0 directMode 0
[TRAINING] alex-System-Product-Name:28355:28425 [2] NCCL INFO [Proxy Service] Device 2 CPU core 2
[TRAINING] alex-System-Product-Name:28356:28430 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 20
[TRAINING] alex-System-Product-Name:28356:28426 [3] NCCL INFO [Proxy Service] Device 3 CPU core 23
[TRAINING] alex-System-Product-Name:28354:28423 [1] NCCL INFO [Proxy Service] Device 1 CPU core 26
[TRAINING] alex-System-Product-Name:28353:28429 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 25
[TRAINING] alex-System-Product-Name:28354:28428 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 21
[TRAINING] alex-System-Product-Name:28355:28427 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 28
[TRAINING] alex-System-Product-Name:28353:28424 [0] NCCL INFO [Proxy Service] Device 0 CPU core 24
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO CC Off, workFifoBytes 1048576
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO ncclCommInitRankConfig comm 0x55e74690efe0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 5000 commId 0x5a414978268db56c - Init COMPLETE
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO ncclCommInitRankConfig comm 0x6329636d67d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1000 commId 0x5a414978268db56c - Init COMPLETE
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO ncclCommInitRankConfig comm 0x635b246730d0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8000 commId 0x5a414978268db56c - Init COMPLETE
[TRAINING] alex-System-Product-Name:28353:28405 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.24 (kernels 0.12, alloc 0.00, bootstrap 0.09, allgathers 0.00, topo 0.02, graphs 0.00, connections 0.00, rest 0.00)
[TRAINING] alex-System-Product-Name:28354:28416 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.11 (kernels 0.07, alloc 0.00, bootstrap 0.02, allgathers 0.00, topo 0.02, graphs 0.00, connections 0.00, rest 0.00)
[TRAINING] alex-System-Product-Name:28355:28418 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.10 (kernels 0.08, alloc 0.00, bootstrap 0.00, allgathers 0.00, topo 0.02, graphs 0.00, connections 0.00, rest 0.00)
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO ncclCommInitRankConfig comm 0x5d0413d26f00 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId 9000 commId 0x5a414978268db56c - Init COMPLETE
[TRAINING] alex-System-Product-Name:28356:28417 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.11 (kernels 0.07, alloc 0.00, bootstrap 0.02, allgathers 0.00, topo 0.02, graphs 0.00, connections 0.00, rest 0.00)
[TRAINING] alex-System-Product-Name:28353:28431 [0] NCCL INFO Channel 01 : 0[0] -> 1[1] via SHM/direct/direct
[TRAINING] alex-System-Product-Name:28355:28432 [2] NCCL INFO Channel 00 : 2[2] -> 3[3] via SHM/direct/direct
[TRAINING] alex-System-Product-Name:28353:28431 [0] NCCL INFO Channel 03 : 0[0] -> 1[1] via SHM/direct/direct
[TRAINING] alex-System-Product-Name:28355:28432 [2] NCCL INFO Channel 02 : 2[2] -> 3[3] via SHM/direct/direct
[TRAINING] alex-System-Product-Name:28355:28432 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM
[TRAINING] alex-System-Product-Name:28354:28434 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM
[TRAINING] alex-System-Product-Name:28356:28433 [3] NCCL INFO Channel 00/0 : 3[3] -> 1[1] via P2P/CUMEM
[TRAINING] alex-System-Product-Name:28353:28431 [0] NCCL INFO Channel 00/0 : 0[0] -> 2[2] via P2P/CUMEM
[TRAINING] alex-System-Product-Name:28355:28432 [2] NCCL INFO Channel 03/0 : 2[2] -> 0[0] via P2P/CUMEM
[TRAINING] alex-System-Product-Name:28354:28434 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM
[TRAINING] alex-System-Product-Name:28356:28433 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM
[TRAINING] alex-System-Product-Name:28353:28431 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM
[TRAINING] alex-System-Product-Name:28354:28434 [1] NCCL INFO Channel 00 : 1[1] -> 0[0] via SHM/direct/direct
[TRAINING] alex-System-Product-Name:28356:28433 [3] NCCL INFO Channel 01 : 3[3] -> 2[2] via SHM/direct/direct
[TRAINING] alex-System-Product-Name:28354:28434 [1] NCCL INFO Channel 02 : 1[1] -> 0[0] via SHM/direct/direct
[TRAINING] alex-System-Product-Name:28356:28433 [3] NCCL INFO Channel 03 : 3[3] -> 2[2] via SHM/direct/direct
[TRAINING] alex-System-Product-Name:28355:28432 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
[TRAINING] alex-System-Product-Name:28354:28434 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
[TRAINING] alex-System-Product-Name:28353:28431 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
[TRAINING] alex-System-Product-Name:28356:28433 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Total data: 4311800 train, 1077950 test rows
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Using full dataset: 1077950 train rows, 269487 test rows per GPU
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ numba.cuda.cudadrv.driver: init
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Total data: 4311800 train, 1077950 test rows
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Using full dataset: 1077950 train rows, 269487 test rows per GPU
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ numba.cuda.cudadrv.driver: init
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Total data: 4311800 train, 1077950 test rows
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Using full dataset: 1077950 train rows, 269487 test rows per GPU
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ numba.cuda.cudadrv.driver: init
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Total data: 4311800 train, 1077950 test rows
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ root           : Using full dataset: 1077950 train rows, 269487 test rows per GPU
[TRAINING] 2025-07-10 22:04:20 [INFO    ] ğŸ”¸ numba.cuda.cudadrv.driver: init
INFO:__main__:ğŸ“Š Starting dashboard...
INFO:__main__:âœ… Dashboard started on http://0.0.0.0:5000
INFO:__main__:ğŸ‰ System startup complete!
INFO:__main__:ğŸ“Š Dashboard: http://0.0.0.0:5000
INFO:__main__:ğŸ“ˆ TensorBoard: http://0.0.0.0:6006
INFO:__main__:ğŸ§  Training: Active
INFO:__main__:============================================================
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
[TRAINING] 2025-07-10 22:04:41 [INFO    ] ğŸ”¸ VISUALIZATION  : ğŸ¨ Visualization system initialized on port 5000
[TRAINING] 2025-07-10 22:04:41 [ERROR   ] ğŸ”¸ VISUALIZATION  : âŒ Failed to start web server: [Errno 98] Address already in use
[TRAINING] 2025-07-10 22:04:41 [INFO    ] ğŸ”¸ email_notifications: Email notifications configured for ali.aloraibi@outlook.com
[TRAINING] 2025-07-10 22:04:41 [INFO    ] ğŸ”¸ email_notifications: Notifications will be sent every 6 hours
[TRAINING] 2025-07-10 22:04:41 [INFO    ] ğŸ”¸ email_notifications: No training metrics available for progress update
[TRAINING] 2025-07-10 22:04:41 [INFO    ] ğŸ”¸ email_notifications: Training monitoring started
[TRAINING] 2025-07-10 22:04:41 [INFO    ] ğŸ”¸ root           : ğŸ“§ Email notifications enabled
[TRAINING] 2025-07-10 22:04:41 [INFO    ] ğŸ”¸ root           : Rank 3 heartbeat - waiting for adaptive training
[TRAINING] 2025-07-10 22:04:41 [INFO    ] ğŸ”¸ adaptive_trainer: Removed old TensorBoard run: ./runs/ga_experiment
[TRAINING] 2025-07-10 22:04:41 [INFO    ] ğŸ”¸ adaptive_trainer: Starting adaptive training
[TRAINING] 2025-07-10 22:04:41 [INFO    ] ğŸ”¸ adaptive_trainer:
[TRAINING] === Adaptive Training Iteration 1/3 ===
[TRAINING] 2025-07-10 22:04:41 [INFO    ] ğŸ”¸ root           : Rank 1 heartbeat - waiting for adaptive training
[TRAINING] 2025-07-10 22:04:41 [INFO    ] ğŸ”¸ root           : Rank 2 heartbeat - waiting for adaptive training
[TRAINING] 2025-07-10 22:04:46 [INFO    ] ğŸ”¸ root           : Rank 3 detected training completion
[TRAINING] 2025-07-10 22:04:46 [INFO    ] ğŸ”¸ root           : Rank 1 detected training completion
[TRAINING] 2025-07-10 22:04:46 [INFO    ] ğŸ”¸ root           : Rank 2 detected training completion
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
[TRAINING] 2025-07-10 22:08:44 [INFO    ] ğŸ”¸ adaptive_trainer: Evaluation results: 149304 profits, total=0.0000
[TRAINING] 2025-07-10 22:08:44 [INFO    ] ğŸ”¸ adaptive_trainer: Metrics: CAGR=0.0000, Sharpe=-5.0000, MDD=0.0000
[TRAINING] 2025-07-10 22:08:44 [INFO    ] ğŸ”¸ adaptive_trainer: Current performance: -0.2500 (best: -0.2500)
[TRAINING] 2025-07-10 22:08:44 [INFO    ] ğŸ”¸ adaptive_trainer: Stagnation: 0, Poor performance: 0
[TRAINING] 2025-07-10 22:08:44 [INFO    ] ğŸ”¸ adaptive_trainer: Method: GA, Entropy: 1.9459
[TRAINING] 2025-07-10 22:08:44 [INFO    ] ğŸ”¸ adaptive_trainer: Switching to PPO due to: ga_solution_refinement
[TRAINING] 2025-07-10 22:08:44 [INFO    ] ğŸ”¸ adaptive_trainer: Switching from GA to PPO
[TRAINING] 2025-07-10 22:08:44 [INFO    ] ğŸ”¸ adaptive_trainer: Starting PPO phase: 150 updates
[TRAINING] 2025-07-10 22:08:44 [INFO    ] ğŸ”¸ policy_gradient_methods: Loaded model from models/ppo_models/adaptive_ppo_model.pth
[TRAINING] Removed old TensorBoard run: ./runs/ppo_rank_0
[TRAINING] 2025-07-10 22:08:44 [INFO    ] ğŸ”¸ policy_gradient_methods: Loaded model from models/ppo_models/adaptive_ppo_model.pth
^AINFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
[TRAINING] 2025-07-10 22:12:41 [INFO    ] ğŸ”¸ adaptive_trainer: Evaluation results: 145752 profits, total=0.0000
[TRAINING] 2025-07-10 22:12:41 [INFO    ] ğŸ”¸ adaptive_trainer: Metrics: CAGR=0.0000, Sharpe=-5.0000, MDD=0.0000
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   1%|          | 10/1024 [00:00<00:15, 65.14it/s, reward=-0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   1%|          | 10/1024 [00:00<00:15, 65.14it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   1%|          | 10/1024 [00:00<00:15, 65.14it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   1%|          | 10/1024 [00:00<00:15, 65.14it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   1%|          | 10/1024 [00:00<00:15, 65.14it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  12%|â–ˆâ–        | 122/1024 [00:00<00:01, 566.42it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  12%|â–ˆâ–        | 122/1024 [00:00<00:01, 566.42it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  12%|â–ˆâ–        | 122/1024 [00:00<00:01, 566.42it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  12%|â–ˆâ–        | 122/1024 [00:00<00:01, 566.42it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  12%|â–ˆâ–        | 122/1024 [00:00<00:01, 566.42it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  21%|â–ˆâ–ˆâ–       | 220/1024 [00:00<00:01, 728.53it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  21%|â–ˆâ–ˆâ–       | 220/1024 [00:00<00:01, 728.53it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  21%|â–ˆâ–ˆâ–       | 220/1024 [00:00<00:01, 728.53it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  21%|â–ˆâ–ˆâ–       | 220/1024 [00:00<00:01, 728.53it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  21%|â–ˆâ–ˆâ–       | 220/1024 [00:00<00:01, 728.53it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  31%|â–ˆâ–ˆâ–ˆ       | 316/1024 [00:00<00:00, 809.98it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  31%|â–ˆâ–ˆâ–ˆ       | 316/1024 [00:00<00:00, 809.98it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  31%|â–ˆâ–ˆâ–ˆ       | 316/1024 [00:00<00:00, 809.98it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  31%|â–ˆâ–ˆâ–ˆ       | 316/1024 [00:00<00:00, 809.98it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  31%|â–ˆâ–ˆâ–ˆ       | 316/1024 [00:00<00:00, 809.98it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 408/1024 [00:00<00:00, 840.24it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 408/1024 [00:00<00:00, 840.24it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 408/1024 [00:00<00:00, 840.24it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 408/1024 [00:00<00:00, 840.24it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 408/1024 [00:00<00:00, 840.24it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 509/1024 [00:00<00:00, 893.96it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 509/1024 [00:00<00:00, 893.96it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 509/1024 [00:00<00:00, 893.96it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 509/1024 [00:00<00:00, 893.96it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 509/1024 [00:00<00:00, 893.96it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 605/1024 [00:00<00:00, 914.82it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 605/1024 [00:00<00:00, 914.82it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 605/1024 [00:00<00:00, 914.82it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 700/1024 [00:00<00:00, 925.07it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 700/1024 [00:00<00:00, 925.07it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 700/1024 [00:00<00:00, 925.07it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 700/1024 [00:00<00:00, 925.07it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 700/1024 [00:00<00:00, 925.07it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 795/1024 [00:00<00:00, 932.71it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 795/1024 [00:00<00:00, 932.71it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 795/1024 [00:00<00:00, 932.71it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 795/1024 [00:01<00:00, 932.71it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 795/1024 [00:01<00:00, 932.71it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 888/1024 [00:01<00:00, 931.18it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 888/1024 [00:01<00:00, 931.18it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 888/1024 [00:01<00:00, 931.18it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 888/1024 [00:01<00:00, 931.18it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 888/1024 [00:01<00:00, 931.18it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 970/1024 [00:01<00:00, 887.26it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 970/1024 [00:01<00:00, 887.26it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 970/1024 [00:01<00:00, 887.26it/s, reward=0.0, eps=0, p_loss=0.000, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1069.33it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1069.33it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1069.33it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1069.33it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1069.33it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  21%|â–ˆâ–ˆ        | 210/1024 [00:00<00:00, 1045.04it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  21%|â–ˆâ–ˆ        | 210/1024 [00:00<00:00, 1045.04it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  21%|â–ˆâ–ˆ        | 210/1024 [00:00<00:00, 1045.04it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  21%|â–ˆâ–ˆ        | 210/1024 [00:00<00:00, 1045.04it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  21%|â–ˆâ–ˆ        | 210/1024 [00:00<00:00, 1045.04it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–ˆ       | 311/1024 [00:00<00:00, 1028.83it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–ˆ       | 311/1024 [00:00<00:00, 1028.83it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–ˆ       | 311/1024 [00:00<00:00, 1028.83it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–ˆ       | 311/1024 [00:00<00:00, 1028.83it/s, reward=-0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–ˆ       | 311/1024 [00:00<00:00, 1028.83it/s, reward=-0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 405/1024 [00:00<00:00, 993.24it/s, reward=-0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 405/1024 [00:00<00:00, 993.24it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 405/1024 [00:00<00:00, 993.24it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 405/1024 [00:00<00:00, 993.24it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 405/1024 [00:00<00:00, 993.24it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 504/1024 [00:00<00:00, 990.89it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 504/1024 [00:00<00:00, 990.89it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 504/1024 [00:00<00:00, 990.89it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 504/1024 [00:00<00:00, 990.89it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 504/1024 [00:00<00:00, 990.89it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 603/1024 [00:00<00:00, 989.85it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 603/1024 [00:00<00:00, 989.85it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 603/1024 [00:00<00:00, 989.85it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686/1024 [00:00<00:00, 935.69it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686/1024 [00:00<00:00, 935.69it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686/1024 [00:00<00:00, 935.69it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686/1024 [00:00<00:00, 935.69it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686/1024 [00:00<00:00, 935.69it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 771/1024 [00:00<00:00, 899.88it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 771/1024 [00:00<00:00, 899.88it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 771/1024 [00:00<00:00, 899.88it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 771/1024 [00:00<00:00, 899.88it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 771/1024 [00:00<00:00, 899.88it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 867/1024 [00:00<00:00, 917.63it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 867/1024 [00:00<00:00, 917.63it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 867/1024 [00:00<00:00, 917.63it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 867/1024 [00:00<00:00, 917.63it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 867/1024 [00:00<00:00, 917.63it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 962/1024 [00:01<00:00, 927.34it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 962/1024 [00:01<00:00, 927.34it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 962/1024 [00:01<00:00, 927.34it/s, reward=0.0, eps=0, p_loss=0.043, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 949.08it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 949.08it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 949.08it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 949.08it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 949.08it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 202/1024 [00:00<00:00, 963.87it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 202/1024 [00:00<00:00, 963.87it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 202/1024 [00:00<00:00, 963.87it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 967.60it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 967.60it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 967.60it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 967.60it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 967.60it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 398/1024 [00:00<00:00, 969.58it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 398/1024 [00:00<00:00, 969.58it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 398/1024 [00:00<00:00, 969.58it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 398/1024 [00:00<00:00, 969.58it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 398/1024 [00:00<00:00, 969.58it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 495/1024 [00:00<00:00, 969.64it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 495/1024 [00:00<00:00, 969.64it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 495/1024 [00:00<00:00, 969.64it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 495/1024 [00:00<00:00, 969.64it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 495/1024 [00:00<00:00, 969.64it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 591/1024 [00:00<00:00, 966.06it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 591/1024 [00:00<00:00, 966.06it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 591/1024 [00:00<00:00, 966.06it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 591/1024 [00:00<00:00, 966.06it/s, reward=-0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 591/1024 [00:00<00:00, 966.06it/s, reward=-0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 685/1024 [00:00<00:00, 957.31it/s, reward=-0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 685/1024 [00:00<00:00, 957.31it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 685/1024 [00:00<00:00, 957.31it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 685/1024 [00:00<00:00, 957.31it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 685/1024 [00:00<00:00, 957.31it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 768/1024 [00:00<00:00, 906.59it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 768/1024 [00:00<00:00, 906.59it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 768/1024 [00:00<00:00, 906.59it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 768/1024 [00:00<00:00, 906.59it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 768/1024 [00:00<00:00, 906.59it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 862/1024 [00:00<00:00, 916.47it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 862/1024 [00:00<00:00, 916.47it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 862/1024 [00:00<00:00, 916.47it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 862/1024 [00:01<00:00, 916.47it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 862/1024 [00:01<00:00, 916.47it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 955/1024 [00:01<00:00, 918.58it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 955/1024 [00:01<00:00, 918.58it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 955/1024 [00:01<00:00, 918.58it/s, reward=0.0, eps=0, p_loss=-0.001, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1048.02it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1048.02it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1048.02it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1048.02it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1048.02it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 202/1024 [00:00<00:00, 998.68it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 202/1024 [00:00<00:00, 998.68it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 202/1024 [00:00<00:00, 998.68it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 202/1024 [00:00<00:00, 998.68it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 202/1024 [00:00<00:00, 998.68it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 301/1024 [00:00<00:00, 994.65it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 301/1024 [00:00<00:00, 994.65it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 301/1024 [00:00<00:00, 994.65it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 399/1024 [00:00<00:00, 988.71it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 399/1024 [00:00<00:00, 988.71it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 399/1024 [00:00<00:00, 988.71it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 399/1024 [00:00<00:00, 988.71it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 399/1024 [00:00<00:00, 988.71it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 497/1024 [00:00<00:00, 983.63it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 497/1024 [00:00<00:00, 983.63it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 497/1024 [00:00<00:00, 983.63it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 497/1024 [00:00<00:00, 983.63it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 497/1024 [00:00<00:00, 983.63it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 594/1024 [00:00<00:00, 977.47it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 594/1024 [00:00<00:00, 977.47it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 594/1024 [00:00<00:00, 977.47it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 594/1024 [00:00<00:00, 977.47it/s, reward=-0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 594/1024 [00:00<00:00, 977.47it/s, reward=-0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 688/1024 [00:00<00:00, 964.60it/s, reward=-0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 688/1024 [00:00<00:00, 964.60it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 688/1024 [00:00<00:00, 964.60it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 688/1024 [00:00<00:00, 964.60it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 688/1024 [00:00<00:00, 964.60it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 783/1024 [00:00<00:00, 958.38it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 783/1024 [00:00<00:00, 958.38it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 783/1024 [00:00<00:00, 958.38it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 783/1024 [00:00<00:00, 958.38it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 783/1024 [00:00<00:00, 958.38it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 876/1024 [00:00<00:00, 947.23it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 876/1024 [00:00<00:00, 947.23it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 876/1024 [00:00<00:00, 947.23it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 876/1024 [00:00<00:00, 947.23it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 876/1024 [00:00<00:00, 947.23it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 968/1024 [00:01<00:00, 906.87it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 968/1024 [00:01<00:00, 906.87it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 968/1024 [00:01<00:00, 906.87it/s, reward=0.0, eps=0, p_loss=-0.000, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 960.15it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 960.15it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 960.15it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 960.15it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 960.15it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 965.03it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 965.03it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 965.03it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 965.03it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 965.03it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 302/1024 [00:00<00:00, 969.86it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 302/1024 [00:00<00:00, 969.86it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 302/1024 [00:00<00:00, 969.86it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 302/1024 [00:00<00:00, 969.86it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 302/1024 [00:00<00:00, 969.86it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 401/1024 [00:00<00:00, 974.08it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 401/1024 [00:00<00:00, 974.08it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 401/1024 [00:00<00:00, 974.08it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 499/1024 [00:00<00:00, 973.93it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 499/1024 [00:00<00:00, 973.93it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 499/1024 [00:00<00:00, 973.93it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 499/1024 [00:00<00:00, 973.93it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 499/1024 [00:00<00:00, 973.93it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 597/1024 [00:00<00:00, 975.00it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 597/1024 [00:00<00:00, 975.00it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 597/1024 [00:00<00:00, 975.00it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 597/1024 [00:00<00:00, 975.00it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 597/1024 [00:00<00:00, 975.00it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 963.53it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 963.53it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 963.53it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 963.53it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 963.53it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 772/1024 [00:00<00:00, 911.33it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 772/1024 [00:00<00:00, 911.33it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 772/1024 [00:00<00:00, 911.33it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 772/1024 [00:00<00:00, 911.33it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 772/1024 [00:00<00:00, 911.33it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 858/1024 [00:00<00:00, 894.35it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 858/1024 [00:00<00:00, 894.35it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 858/1024 [00:00<00:00, 894.35it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 858/1024 [00:01<00:00, 894.35it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 858/1024 [00:01<00:00, 894.35it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 952/1024 [00:01<00:00, 906.85it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 952/1024 [00:01<00:00, 906.85it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 952/1024 [00:01<00:00, 906.85it/s, reward=0.0, eps=0, p_loss=-0.031, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1048.26it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1048.26it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1048.26it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1048.26it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1048.26it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1012.29it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1012.29it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1012.29it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1012.29it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1012.29it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 302/1024 [00:00<00:00, 993.91it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 302/1024 [00:00<00:00, 993.91it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 302/1024 [00:00<00:00, 993.91it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 986.97it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 986.97it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 986.97it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 986.97it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 986.97it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 983.99it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 983.99it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 983.99it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 983.99it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 983.99it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 593/1024 [00:00<00:00, 972.43it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 593/1024 [00:00<00:00, 972.43it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 593/1024 [00:00<00:00, 972.43it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 593/1024 [00:00<00:00, 972.43it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 593/1024 [00:00<00:00, 972.43it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 689/1024 [00:00<00:00, 966.65it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 689/1024 [00:00<00:00, 966.65it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 689/1024 [00:00<00:00, 966.65it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 689/1024 [00:00<00:00, 966.65it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 689/1024 [00:00<00:00, 966.65it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 782/1024 [00:00<00:00, 953.01it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 782/1024 [00:00<00:00, 953.01it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 782/1024 [00:00<00:00, 953.01it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 782/1024 [00:00<00:00, 953.01it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 782/1024 [00:00<00:00, 953.01it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 870/1024 [00:00<00:00, 919.41it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 870/1024 [00:00<00:00, 919.41it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 870/1024 [00:00<00:00, 919.41it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 870/1024 [00:01<00:00, 919.41it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 870/1024 [00:01<00:00, 919.41it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 959/1024 [00:01<00:00, 908.82it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 959/1024 [00:01<00:00, 908.82it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 959/1024 [00:01<00:00, 908.82it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1064.19it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1064.19it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1064.19it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 192/1024 [00:00<00:00, 937.24it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 192/1024 [00:00<00:00, 937.24it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 192/1024 [00:00<00:00, 937.24it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 192/1024 [00:00<00:00, 937.24it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 192/1024 [00:00<00:00, 937.24it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  28%|â–ˆâ–ˆâ–Š       | 289/1024 [00:00<00:00, 949.91it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  28%|â–ˆâ–ˆâ–Š       | 289/1024 [00:00<00:00, 949.91it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  28%|â–ˆâ–ˆâ–Š       | 289/1024 [00:00<00:00, 949.91it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  28%|â–ˆâ–ˆâ–Š       | 289/1024 [00:00<00:00, 949.91it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  28%|â–ˆâ–ˆâ–Š       | 289/1024 [00:00<00:00, 949.91it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 373/1024 [00:00<00:00, 905.39it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 373/1024 [00:00<00:00, 905.39it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 373/1024 [00:00<00:00, 905.39it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 373/1024 [00:00<00:00, 905.39it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 373/1024 [00:00<00:00, 905.39it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 471/1024 [00:00<00:00, 930.15it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 471/1024 [00:00<00:00, 930.15it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 471/1024 [00:00<00:00, 930.15it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 471/1024 [00:00<00:00, 930.15it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 471/1024 [00:00<00:00, 930.15it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 568/1024 [00:00<00:00, 941.89it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 568/1024 [00:00<00:00, 941.89it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 568/1024 [00:00<00:00, 941.89it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 568/1024 [00:00<00:00, 941.89it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 568/1024 [00:00<00:00, 941.89it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 663/1024 [00:00<00:00, 944.45it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 663/1024 [00:00<00:00, 944.45it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 663/1024 [00:00<00:00, 944.45it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 663/1024 [00:00<00:00, 944.45it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 663/1024 [00:00<00:00, 944.45it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 757/1024 [00:00<00:00, 940.92it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 757/1024 [00:00<00:00, 940.92it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 757/1024 [00:00<00:00, 940.92it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 757/1024 [00:00<00:00, 940.92it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 757/1024 [00:00<00:00, 940.92it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 852/1024 [00:00<00:00, 941.99it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 852/1024 [00:00<00:00, 941.99it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 852/1024 [00:00<00:00, 941.99it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944/1024 [00:01<00:00, 934.10it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944/1024 [00:01<00:00, 934.10it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944/1024 [00:01<00:00, 934.10it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944/1024 [00:01<00:00, 934.10it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944/1024 [00:01<00:00, 934.10it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1021/1024 [00:01<00:00, 882.38it/s, reward=0.0, eps=0, p_loss=-0.019, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 103/1024 [00:00<00:00, 968.24it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 103/1024 [00:00<00:00, 968.24it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 103/1024 [00:00<00:00, 968.24it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 199/1024 [00:00<00:00, 960.23it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 199/1024 [00:00<00:00, 960.23it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 199/1024 [00:00<00:00, 960.23it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 199/1024 [00:00<00:00, 960.23it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 199/1024 [00:00<00:00, 960.23it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 295/1024 [00:00<00:00, 959.52it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 295/1024 [00:00<00:00, 959.52it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 295/1024 [00:00<00:00, 959.52it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 295/1024 [00:00<00:00, 959.52it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 295/1024 [00:00<00:00, 959.52it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 392/1024 [00:00<00:00, 962.38it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 392/1024 [00:00<00:00, 962.38it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 392/1024 [00:00<00:00, 962.38it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 392/1024 [00:00<00:00, 962.38it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 392/1024 [00:00<00:00, 962.38it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 489/1024 [00:00<00:00, 964.14it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 489/1024 [00:00<00:00, 964.14it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 489/1024 [00:00<00:00, 964.14it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 489/1024 [00:00<00:00, 964.14it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 489/1024 [00:00<00:00, 964.14it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 587/1024 [00:00<00:00, 967.02it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 587/1024 [00:00<00:00, 967.02it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 587/1024 [00:00<00:00, 967.02it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 587/1024 [00:00<00:00, 967.02it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 587/1024 [00:00<00:00, 967.02it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 680/1024 [00:00<00:00, 954.96it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 680/1024 [00:00<00:00, 954.96it/s, reward=-0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 680/1024 [00:00<00:00, 954.96it/s, reward=-0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 680/1024 [00:00<00:00, 954.96it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 680/1024 [00:00<00:00, 954.96it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 767/1024 [00:00<00:00, 922.60it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 767/1024 [00:00<00:00, 922.60it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 767/1024 [00:00<00:00, 922.60it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 767/1024 [00:00<00:00, 922.60it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 767/1024 [00:00<00:00, 922.60it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 854/1024 [00:00<00:00, 906.14it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 854/1024 [00:00<00:00, 906.14it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 854/1024 [00:00<00:00, 906.14it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 947/1024 [00:01<00:00, 913.46it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 947/1024 [00:01<00:00, 913.46it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 947/1024 [00:01<00:00, 913.46it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 947/1024 [00:01<00:00, 913.46it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 947/1024 [00:01<00:00, 913.46it/s, reward=0.0, eps=0, p_loss=-0.014, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 106/1024 [00:00<00:00, 992.64it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 106/1024 [00:00<00:00, 992.64it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 106/1024 [00:00<00:00, 992.64it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 199/1024 [00:00<00:00, 955.83it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 199/1024 [00:00<00:00, 955.83it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 199/1024 [00:00<00:00, 955.83it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 199/1024 [00:00<00:00, 955.83it/s, reward=-0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 199/1024 [00:00<00:00, 955.83it/s, reward=-0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 296/1024 [00:00<00:00, 961.49it/s, reward=-0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 296/1024 [00:00<00:00, 961.49it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 296/1024 [00:00<00:00, 961.49it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 296/1024 [00:00<00:00, 961.49it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 296/1024 [00:00<00:00, 961.49it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 394/1024 [00:00<00:00, 967.36it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 394/1024 [00:00<00:00, 967.36it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 394/1024 [00:00<00:00, 967.36it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 394/1024 [00:00<00:00, 967.36it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 394/1024 [00:00<00:00, 967.36it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 492/1024 [00:00<00:00, 970.57it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 492/1024 [00:00<00:00, 970.57it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 492/1024 [00:00<00:00, 970.57it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 492/1024 [00:00<00:00, 970.57it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 492/1024 [00:00<00:00, 970.57it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 589/1024 [00:00<00:00, 968.86it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 589/1024 [00:00<00:00, 968.86it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 589/1024 [00:00<00:00, 968.86it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 589/1024 [00:00<00:00, 968.86it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 589/1024 [00:00<00:00, 968.86it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 685/1024 [00:00<00:00, 963.63it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 685/1024 [00:00<00:00, 963.63it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 685/1024 [00:00<00:00, 963.63it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 685/1024 [00:00<00:00, 963.63it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 685/1024 [00:00<00:00, 963.63it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 779/1024 [00:00<00:00, 955.13it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 779/1024 [00:00<00:00, 955.13it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 779/1024 [00:00<00:00, 955.13it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 779/1024 [00:00<00:00, 955.13it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 779/1024 [00:00<00:00, 955.13it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 866/1024 [00:00<00:00, 925.52it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 866/1024 [00:00<00:00, 925.52it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 866/1024 [00:00<00:00, 925.52it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 866/1024 [00:01<00:00, 925.52it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 866/1024 [00:01<00:00, 925.52it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 952/1024 [00:01<00:00, 904.20it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 952/1024 [00:01<00:00, 904.20it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 952/1024 [00:01<00:00, 904.20it/s, reward=0.0, eps=0, p_loss=0.018, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1054.56it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1054.56it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1054.56it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1054.56it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1054.56it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1008.92it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1008.92it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1008.92it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1008.92it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1008.92it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 303/1024 [00:00<00:00, 994.17it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 303/1024 [00:00<00:00, 994.17it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 303/1024 [00:00<00:00, 994.17it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 303/1024 [00:00<00:00, 994.17it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 303/1024 [00:00<00:00, 994.17it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 401/1024 [00:00<00:00, 988.19it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 401/1024 [00:00<00:00, 988.19it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 401/1024 [00:00<00:00, 988.19it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 979.08it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 979.08it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 979.08it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 979.08it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 979.08it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 595/1024 [00:00<00:00, 971.71it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 595/1024 [00:00<00:00, 971.71it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 595/1024 [00:00<00:00, 971.71it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 595/1024 [00:00<00:00, 971.71it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 595/1024 [00:00<00:00, 971.71it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 966.42it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 966.42it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 966.42it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 966.42it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 966.42it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 771/1024 [00:00<00:00, 911.58it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 771/1024 [00:00<00:00, 911.58it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 771/1024 [00:00<00:00, 911.58it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 771/1024 [00:00<00:00, 911.58it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 771/1024 [00:00<00:00, 911.58it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:00<00:00, 916.38it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:00<00:00, 916.38it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:00<00:00, 916.38it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:00<00:00, 916.38it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:00<00:00, 916.38it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 959/1024 [00:01<00:00, 925.11it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 959/1024 [00:01<00:00, 925.11it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 959/1024 [00:01<00:00, 925.11it/s, reward=0.0, eps=0, p_loss=-0.025, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1066.46it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1066.46it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1066.46it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1066.46it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1066.46it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1007.93it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1007.93it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1007.93it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1007.93it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1007.93it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 302/1024 [00:00<00:00, 995.04it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 302/1024 [00:00<00:00, 995.04it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 302/1024 [00:00<00:00, 995.04it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 987.97it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 987.97it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 987.97it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 987.97it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 987.97it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 978.59it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 978.59it/s, reward=-0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 978.59it/s, reward=-0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 978.59it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 978.59it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 582/1024 [00:00<00:00, 931.16it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 582/1024 [00:00<00:00, 931.16it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 582/1024 [00:00<00:00, 931.16it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 582/1024 [00:00<00:00, 931.16it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 582/1024 [00:00<00:00, 931.16it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 663/1024 [00:00<00:00, 889.92it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 663/1024 [00:00<00:00, 889.92it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 663/1024 [00:00<00:00, 889.92it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 663/1024 [00:00<00:00, 889.92it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 663/1024 [00:00<00:00, 889.92it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 757/1024 [00:00<00:00, 903.98it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 757/1024 [00:00<00:00, 903.98it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 757/1024 [00:00<00:00, 903.98it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 757/1024 [00:00<00:00, 903.98it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 757/1024 [00:00<00:00, 903.98it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 852/1024 [00:00<00:00, 917.27it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 852/1024 [00:00<00:00, 917.27it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 852/1024 [00:00<00:00, 917.27it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 945/1024 [00:01<00:00, 920.42it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 945/1024 [00:01<00:00, 920.42it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 945/1024 [00:01<00:00, 920.42it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 945/1024 [00:01<00:00, 920.42it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 945/1024 [00:01<00:00, 920.42it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1023/1024 [00:01<00:00, 876.34it/s, reward=0.0, eps=0, p_loss=-0.027, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 106/1024 [00:00<00:00, 945.01it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 106/1024 [00:00<00:00, 945.01it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 106/1024 [00:00<00:00, 945.01it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 106/1024 [00:00<00:00, 945.01it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 106/1024 [00:00<00:00, 945.01it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 958.24it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 958.24it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 958.24it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 958.24it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 958.24it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 301/1024 [00:00<00:00, 964.75it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 301/1024 [00:00<00:00, 964.75it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 301/1024 [00:00<00:00, 964.75it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 971.57it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 971.57it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 971.57it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 971.57it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 971.57it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 972.23it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 972.23it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 972.23it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 972.23it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 498/1024 [00:00<00:00, 972.23it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 595/1024 [00:00<00:00, 968.93it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 595/1024 [00:00<00:00, 968.93it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 595/1024 [00:00<00:00, 968.93it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 595/1024 [00:00<00:00, 968.93it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 595/1024 [00:00<00:00, 968.93it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 963.57it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 963.57it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 963.57it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 963.57it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 963.57it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 771/1024 [00:00<00:00, 909.93it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 771/1024 [00:00<00:00, 909.93it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 771/1024 [00:00<00:00, 909.93it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 771/1024 [00:00<00:00, 909.93it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 771/1024 [00:00<00:00, 909.93it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:00<00:00, 915.11it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:00<00:00, 915.11it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=88%]
INFO:__main__:ğŸ“Š System Status:
INFO:__main__:   Tensorboard: ğŸŸ¢ Running
INFO:__main__:   Training: ğŸŸ¢ Running
INFO:__main__:   Dashboard: ğŸŸ¢ Running
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:00<00:00, 915.11it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:01<00:00, 915.11it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:01<00:00, 915.11it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 957/1024 [00:01<00:00, 917.33it/s, reward=0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 957/1024 [00:01<00:00, 917.33it/s, reward=-0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 957/1024 [00:01<00:00, 917.33it/s, reward=-0.0, eps=0, p_loss=0.023, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1026.15it/s, reward=-0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1026.15it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1026.15it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1026.15it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1026.15it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 979.88it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 979.88it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 979.88it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 979.88it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 979.88it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 304/1024 [00:00<00:00, 991.32it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 304/1024 [00:00<00:00, 991.32it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 304/1024 [00:00<00:00, 991.32it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 304/1024 [00:00<00:00, 991.32it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 304/1024 [00:00<00:00, 991.32it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 404/1024 [00:00<00:00, 992.79it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 404/1024 [00:00<00:00, 992.79it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 404/1024 [00:00<00:00, 992.79it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 404/1024 [00:00<00:00, 992.79it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 404/1024 [00:00<00:00, 992.79it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 502/1024 [00:00<00:00, 985.56it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 502/1024 [00:00<00:00, 985.56it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 502/1024 [00:00<00:00, 985.56it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 599/1024 [00:00<00:00, 979.19it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 599/1024 [00:00<00:00, 979.19it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 599/1024 [00:00<00:00, 979.19it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 599/1024 [00:00<00:00, 979.19it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 599/1024 [00:00<00:00, 979.19it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 693/1024 [00:00<00:00, 965.09it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 693/1024 [00:00<00:00, 965.09it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 693/1024 [00:00<00:00, 965.09it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 693/1024 [00:00<00:00, 965.09it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 693/1024 [00:00<00:00, 965.09it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 786/1024 [00:00<00:00, 953.13it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 786/1024 [00:00<00:00, 953.13it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 786/1024 [00:00<00:00, 953.13it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 786/1024 [00:00<00:00, 953.13it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 786/1024 [00:00<00:00, 953.13it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 879/1024 [00:00<00:00, 945.50it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 879/1024 [00:00<00:00, 945.50it/s, reward=-0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 879/1024 [00:00<00:00, 945.50it/s, reward=-0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 879/1024 [00:00<00:00, 945.50it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 879/1024 [00:00<00:00, 945.50it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 966/1024 [00:01<00:00, 900.82it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 966/1024 [00:01<00:00, 900.82it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 966/1024 [00:01<00:00, 900.82it/s, reward=0.0, eps=0, p_loss=-0.039, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1042.36it/s, reward=-0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1042.36it/s, reward=-0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1042.36it/s, reward=-0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1042.36it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1042.36it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1010.14it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1010.14it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1010.14it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 985.00it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 985.00it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 985.00it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 985.00it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 985.00it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1024 [00:00<00:00, 976.93it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1024 [00:00<00:00, 976.93it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1024 [00:00<00:00, 976.93it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1024 [00:00<00:00, 976.93it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1024 [00:00<00:00, 976.93it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 480/1024 [00:00<00:00, 923.28it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 480/1024 [00:00<00:00, 923.28it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 480/1024 [00:00<00:00, 923.28it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 480/1024 [00:00<00:00, 923.28it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 480/1024 [00:00<00:00, 923.28it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 563/1024 [00:00<00:00, 890.03it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 563/1024 [00:00<00:00, 890.03it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 563/1024 [00:00<00:00, 890.03it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 563/1024 [00:00<00:00, 890.03it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 563/1024 [00:00<00:00, 890.03it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 659/1024 [00:00<00:00, 911.53it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 659/1024 [00:00<00:00, 911.53it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 659/1024 [00:00<00:00, 911.53it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 659/1024 [00:00<00:00, 911.53it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 659/1024 [00:00<00:00, 911.53it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 752/1024 [00:00<00:00, 915.63it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 752/1024 [00:00<00:00, 915.63it/s, reward=-0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 752/1024 [00:00<00:00, 915.63it/s, reward=-0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 843/1024 [00:00<00:00, 913.61it/s, reward=-0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 843/1024 [00:00<00:00, 913.61it/s, reward=-0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 843/1024 [00:00<00:00, 913.61it/s, reward=-0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 843/1024 [00:00<00:00, 913.61it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 843/1024 [00:00<00:00, 913.61it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 920/1024 [00:01<00:00, 868.31it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 920/1024 [00:01<00:00, 868.31it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 920/1024 [00:01<00:00, 868.31it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 920/1024 [00:01<00:00, 868.31it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 920/1024 [00:01<00:00, 868.31it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1012/1024 [00:01<00:00, 883.97it/s, reward=0.0, eps=0, p_loss=-0.016, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   9%|â–‰         | 92/1024 [00:00<00:01, 914.20it/s, reward=-0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   9%|â–‰         | 92/1024 [00:00<00:01, 914.20it/s, reward=-0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   9%|â–‰         | 92/1024 [00:00<00:01, 914.20it/s, reward=-0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   9%|â–‰         | 92/1024 [00:00<00:01, 914.20it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:   9%|â–‰         | 92/1024 [00:00<00:01, 914.20it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  18%|â–ˆâ–Š        | 189/1024 [00:00<00:00, 946.49it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  18%|â–ˆâ–Š        | 189/1024 [00:00<00:00, 946.49it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  18%|â–ˆâ–Š        | 189/1024 [00:00<00:00, 946.49it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  18%|â–ˆâ–Š        | 189/1024 [00:00<00:00, 946.49it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  18%|â–ˆâ–Š        | 189/1024 [00:00<00:00, 946.49it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  27%|â–ˆâ–ˆâ–‹       | 273/1024 [00:00<00:00, 895.39it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  27%|â–ˆâ–ˆâ–‹       | 273/1024 [00:00<00:00, 895.39it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  27%|â–ˆâ–ˆâ–‹       | 273/1024 [00:00<00:00, 895.39it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  27%|â–ˆâ–ˆâ–‹       | 273/1024 [00:00<00:00, 895.39it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  27%|â–ˆâ–ˆâ–‹       | 273/1024 [00:00<00:00, 895.39it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 371/1024 [00:00<00:00, 926.59it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 371/1024 [00:00<00:00, 926.59it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 371/1024 [00:00<00:00, 926.59it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 371/1024 [00:00<00:00, 926.59it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 371/1024 [00:00<00:00, 926.59it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 469/1024 [00:00<00:00, 945.19it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 469/1024 [00:00<00:00, 945.19it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 469/1024 [00:00<00:00, 945.19it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 469/1024 [00:00<00:00, 945.19it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 469/1024 [00:00<00:00, 945.19it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 564/1024 [00:00<00:00, 945.99it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 564/1024 [00:00<00:00, 945.99it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 564/1024 [00:00<00:00, 945.99it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 564/1024 [00:00<00:00, 945.99it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 564/1024 [00:00<00:00, 945.99it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 661/1024 [00:00<00:00, 952.45it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 661/1024 [00:00<00:00, 952.45it/s, reward=0.1, eps=0, p_loss=0.004, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 661/1024 [00:00<00:00, 952.45it/s, reward=0.1, eps=0, p_loss=0.004, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 661/1024 [00:00<00:00, 952.45it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 661/1024 [00:00<00:00, 952.45it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 754/1024 [00:00<00:00, 944.90it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 754/1024 [00:00<00:00, 944.90it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 754/1024 [00:00<00:00, 944.90it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 847/1024 [00:00<00:00, 938.93it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 847/1024 [00:00<00:00, 938.93it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 847/1024 [00:00<00:00, 938.93it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 847/1024 [00:00<00:00, 938.93it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 847/1024 [00:00<00:00, 938.93it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 926/1024 [00:01<00:00, 893.02it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 926/1024 [00:01<00:00, 893.02it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 926/1024 [00:01<00:00, 893.02it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 926/1024 [00:01<00:00, 893.02it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 926/1024 [00:01<00:00, 893.02it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1019/1024 [00:01<00:00, 902.85it/s, reward=0.0, eps=0, p_loss=0.004, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1067.93it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1067.93it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1067.93it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1067.93it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1067.93it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 1003.05it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 1003.05it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 1003.05it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 1003.05it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 1003.05it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 301/1024 [00:00<00:00, 992.36it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 301/1024 [00:00<00:00, 992.36it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 301/1024 [00:00<00:00, 992.36it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 989.01it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 989.01it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 989.01it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 989.01it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 989.01it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 496/1024 [00:00<00:00, 977.79it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 496/1024 [00:00<00:00, 977.79it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 496/1024 [00:00<00:00, 977.79it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 496/1024 [00:00<00:00, 977.79it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 496/1024 [00:00<00:00, 977.79it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 592/1024 [00:00<00:00, 971.05it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 592/1024 [00:00<00:00, 971.05it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 592/1024 [00:00<00:00, 971.05it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 592/1024 [00:00<00:00, 971.05it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 592/1024 [00:00<00:00, 971.05it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686/1024 [00:00<00:00, 960.15it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686/1024 [00:00<00:00, 960.15it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686/1024 [00:00<00:00, 960.15it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686/1024 [00:00<00:00, 960.15it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686/1024 [00:00<00:00, 960.15it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 780/1024 [00:00<00:00, 951.58it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 780/1024 [00:00<00:00, 951.58it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 780/1024 [00:00<00:00, 951.58it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 780/1024 [00:00<00:00, 951.58it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 780/1024 [00:00<00:00, 951.58it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 870/1024 [00:00<00:00, 923.93it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 870/1024 [00:00<00:00, 923.93it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 870/1024 [00:00<00:00, 923.93it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 870/1024 [00:01<00:00, 923.93it/s, reward=-0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 870/1024 [00:01<00:00, 923.93it/s, reward=-0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 955/1024 [00:01<00:00, 900.81it/s, reward=-0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 955/1024 [00:01<00:00, 900.81it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 955/1024 [00:01<00:00, 900.81it/s, reward=0.0, eps=0, p_loss=0.007, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1069.92it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1069.92it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1069.92it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1069.92it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 107/1024 [00:00<00:00, 1069.92it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1014.23it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1014.23it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1014.23it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1014.23it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1014.23it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 302/1024 [00:00<00:00, 991.15it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 302/1024 [00:00<00:00, 991.15it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 302/1024 [00:00<00:00, 991.15it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 986.75it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 986.75it/s, reward=-0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 986.75it/s, reward=-0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 986.75it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 986.75it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 483/1024 [00:00<00:00, 928.38it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 483/1024 [00:00<00:00, 928.38it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 483/1024 [00:00<00:00, 928.38it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 483/1024 [00:00<00:00, 928.38it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 483/1024 [00:00<00:00, 928.38it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 567/1024 [00:00<00:00, 897.62it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 567/1024 [00:00<00:00, 897.62it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 567/1024 [00:00<00:00, 897.62it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 567/1024 [00:00<00:00, 897.62it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 567/1024 [00:00<00:00, 897.62it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 663/1024 [00:00<00:00, 917.36it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 663/1024 [00:00<00:00, 917.36it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 663/1024 [00:00<00:00, 917.36it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 663/1024 [00:00<00:00, 917.36it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 663/1024 [00:00<00:00, 917.36it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 757/1024 [00:00<00:00, 924.48it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 757/1024 [00:00<00:00, 924.48it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 757/1024 [00:00<00:00, 924.48it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 850/1024 [00:00<00:00, 924.90it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 850/1024 [00:00<00:00, 924.90it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 850/1024 [00:00<00:00, 924.90it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 850/1024 [00:00<00:00, 924.90it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 850/1024 [00:00<00:00, 924.90it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944/1024 [00:01<00:00, 927.71it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944/1024 [00:01<00:00, 927.71it/s, reward=-0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944/1024 [00:01<00:00, 927.71it/s, reward=-0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944/1024 [00:01<00:00, 927.71it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944/1024 [00:01<00:00, 927.71it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1022/1024 [00:01<00:00, 882.57it/s, reward=0.0, eps=0, p_loss=0.008, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1074.08it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1074.08it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1074.08it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1074.08it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1074.08it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1009.79it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1009.79it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1009.79it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1009.79it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1009.79it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 303/1024 [00:00<00:00, 992.48it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 303/1024 [00:00<00:00, 992.48it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 303/1024 [00:00<00:00, 992.48it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 981.20it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 981.20it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 981.20it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 981.20it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 981.20it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 499/1024 [00:00<00:00, 984.24it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 499/1024 [00:00<00:00, 984.24it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 499/1024 [00:00<00:00, 984.24it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 499/1024 [00:00<00:00, 984.24it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 499/1024 [00:00<00:00, 984.24it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 596/1024 [00:00<00:00, 978.98it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 596/1024 [00:00<00:00, 978.98it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 596/1024 [00:00<00:00, 978.98it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 596/1024 [00:00<00:00, 978.98it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 596/1024 [00:00<00:00, 978.98it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 968.18it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 968.18it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 968.18it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 968.18it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 691/1024 [00:00<00:00, 968.18it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 785/1024 [00:00<00:00, 957.02it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 785/1024 [00:00<00:00, 957.02it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 785/1024 [00:00<00:00, 957.02it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 785/1024 [00:00<00:00, 957.02it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 785/1024 [00:00<00:00, 957.02it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 879/1024 [00:00<00:00, 950.10it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 879/1024 [00:00<00:00, 950.10it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 879/1024 [00:00<00:00, 950.10it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 879/1024 [00:00<00:00, 950.10it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 879/1024 [00:00<00:00, 950.10it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 967/1024 [00:01<00:00, 905.75it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 967/1024 [00:01<00:00, 905.75it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 967/1024 [00:01<00:00, 905.75it/s, reward=0.0, eps=0, p_loss=-0.015, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 1037.96it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 1037.96it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 1037.96it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 1037.96it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 1037.96it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 202/1024 [00:00<00:00, 1001.49it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 202/1024 [00:00<00:00, 1001.49it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 202/1024 [00:00<00:00, 1001.49it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 299/1024 [00:00<00:00, 984.51it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 299/1024 [00:00<00:00, 984.51it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 299/1024 [00:00<00:00, 984.51it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 299/1024 [00:00<00:00, 984.51it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 299/1024 [00:00<00:00, 984.51it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1024 [00:00<00:00, 980.27it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1024 [00:00<00:00, 980.27it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1024 [00:00<00:00, 980.27it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1024 [00:00<00:00, 980.27it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1024 [00:00<00:00, 980.27it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 494/1024 [00:00<00:00, 974.89it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 494/1024 [00:00<00:00, 974.89it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 494/1024 [00:00<00:00, 974.89it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 494/1024 [00:00<00:00, 974.89it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 494/1024 [00:00<00:00, 974.89it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 591/1024 [00:00<00:00, 971.26it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 591/1024 [00:00<00:00, 971.26it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 591/1024 [00:00<00:00, 971.26it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 591/1024 [00:00<00:00, 971.26it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 591/1024 [00:00<00:00, 971.26it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 687/1024 [00:00<00:00, 967.37it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 687/1024 [00:00<00:00, 967.37it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 687/1024 [00:00<00:00, 967.37it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 687/1024 [00:00<00:00, 967.37it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 687/1024 [00:00<00:00, 967.37it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 781/1024 [00:00<00:00, 956.55it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 781/1024 [00:00<00:00, 956.55it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 781/1024 [00:00<00:00, 956.55it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 781/1024 [00:00<00:00, 956.55it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 781/1024 [00:00<00:00, 956.55it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:00<00:00, 905.59it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:00<00:00, 905.59it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:00<00:00, 905.59it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:01<00:00, 905.59it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:01<00:00, 905.59it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 957/1024 [00:01<00:00, 912.05it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 957/1024 [00:01<00:00, 912.05it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 957/1024 [00:01<00:00, 912.05it/s, reward=0.0, eps=0, p_loss=0.003, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1046.11it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1046.11it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 105/1024 [00:00<00:00, 1046.11it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  18%|â–ˆâ–Š        | 189/1024 [00:00<00:00, 923.71it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  18%|â–ˆâ–Š        | 189/1024 [00:00<00:00, 923.71it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  18%|â–ˆâ–Š        | 189/1024 [00:00<00:00, 923.71it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  18%|â–ˆâ–Š        | 189/1024 [00:00<00:00, 923.71it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  18%|â–ˆâ–Š        | 189/1024 [00:00<00:00, 923.71it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  27%|â–ˆâ–ˆâ–‹       | 275/1024 [00:00<00:00, 892.98it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  27%|â–ˆâ–ˆâ–‹       | 275/1024 [00:00<00:00, 892.98it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  27%|â–ˆâ–ˆâ–‹       | 275/1024 [00:00<00:00, 892.98it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  27%|â–ˆâ–ˆâ–‹       | 275/1024 [00:00<00:00, 892.98it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  27%|â–ˆâ–ˆâ–‹       | 275/1024 [00:00<00:00, 892.98it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 372/1024 [00:00<00:00, 920.51it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 372/1024 [00:00<00:00, 920.51it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 372/1024 [00:00<00:00, 920.51it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 372/1024 [00:00<00:00, 920.51it/s, reward=-0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 372/1024 [00:00<00:00, 920.51it/s, reward=-0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 457/1024 [00:00<00:00, 894.38it/s, reward=-0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 457/1024 [00:00<00:00, 894.38it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 457/1024 [00:00<00:00, 894.38it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 457/1024 [00:00<00:00, 894.38it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 457/1024 [00:00<00:00, 894.38it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 555/1024 [00:00<00:00, 921.93it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 555/1024 [00:00<00:00, 921.93it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 555/1024 [00:00<00:00, 921.93it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 649/1024 [00:00<00:00, 926.81it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 649/1024 [00:00<00:00, 926.81it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 649/1024 [00:00<00:00, 926.81it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 649/1024 [00:00<00:00, 926.81it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 649/1024 [00:00<00:00, 926.81it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 728/1024 [00:00<00:00, 882.25it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 728/1024 [00:00<00:00, 882.25it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 728/1024 [00:00<00:00, 882.25it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 728/1024 [00:00<00:00, 882.25it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 728/1024 [00:00<00:00, 882.25it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 822/1024 [00:00<00:00, 898.65it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 822/1024 [00:00<00:00, 898.65it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 822/1024 [00:00<00:00, 898.65it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 822/1024 [00:00<00:00, 898.65it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 822/1024 [00:00<00:00, 898.65it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 916/1024 [00:01<00:00, 910.60it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 916/1024 [00:01<00:00, 910.60it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 916/1024 [00:01<00:00, 910.60it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 916/1024 [00:01<00:00, 910.60it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 916/1024 [00:01<00:00, 910.60it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1009/1024 [00:01<00:00, 914.82it/s, reward=0.0, eps=0, p_loss=-0.046, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 106/1024 [00:00<00:00, 1054.37it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 106/1024 [00:00<00:00, 1054.37it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 106/1024 [00:00<00:00, 1054.37it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 106/1024 [00:00<00:00, 1054.37it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 106/1024 [00:00<00:00, 1054.37it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1015.90it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1015.90it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1015.90it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1015.90it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 205/1024 [00:00<00:00, 1015.90it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 303/1024 [00:00<00:00, 997.76it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 303/1024 [00:00<00:00, 997.76it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–‰       | 303/1024 [00:00<00:00, 997.76it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 984.89it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 984.89it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 984.89it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 984.89it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 984.89it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 496/1024 [00:00<00:00, 975.94it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 496/1024 [00:00<00:00, 975.94it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 496/1024 [00:00<00:00, 975.94it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 496/1024 [00:00<00:00, 975.94it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 496/1024 [00:00<00:00, 975.94it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 594/1024 [00:00<00:00, 975.41it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 594/1024 [00:00<00:00, 975.41it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 594/1024 [00:00<00:00, 975.41it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 594/1024 [00:00<00:00, 975.41it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 594/1024 [00:00<00:00, 975.41it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 690/1024 [00:00<00:00, 968.18it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 690/1024 [00:00<00:00, 968.18it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 690/1024 [00:00<00:00, 968.18it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 690/1024 [00:00<00:00, 968.18it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 690/1024 [00:00<00:00, 968.18it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 784/1024 [00:00<00:00, 958.74it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 784/1024 [00:00<00:00, 958.74it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 784/1024 [00:00<00:00, 958.74it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 784/1024 [00:00<00:00, 958.74it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 784/1024 [00:00<00:00, 958.74it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 868/1024 [00:00<00:00, 905.89it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 868/1024 [00:00<00:00, 905.89it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 868/1024 [00:00<00:00, 905.89it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 868/1024 [00:01<00:00, 905.89it/s, reward=0.1, eps=0, p_loss=-0.006, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 868/1024 [00:01<00:00, 905.89it/s, reward=0.1, eps=0, p_loss=-0.006, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 960/1024 [00:01<00:00, 908.77it/s, reward=0.1, eps=0, p_loss=-0.006, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 960/1024 [00:01<00:00, 908.77it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 960/1024 [00:01<00:00, 908.77it/s, reward=0.0, eps=0, p_loss=-0.006, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 941.71it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 941.71it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 941.71it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 941.71it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 941.71it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 202/1024 [00:00<00:00, 963.29it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 202/1024 [00:00<00:00, 963.29it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 202/1024 [00:00<00:00, 963.29it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 968.32it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 968.32it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 968.32it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 968.32it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 968.32it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 398/1024 [00:00<00:00, 972.03it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 398/1024 [00:00<00:00, 972.03it/s, reward=-0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 398/1024 [00:00<00:00, 972.03it/s, reward=-0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 398/1024 [00:00<00:00, 972.03it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 398/1024 [00:00<00:00, 972.03it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 495/1024 [00:00<00:00, 968.71it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 495/1024 [00:00<00:00, 968.71it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 495/1024 [00:00<00:00, 968.71it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 495/1024 [00:00<00:00, 968.71it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 495/1024 [00:00<00:00, 968.71it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 590/1024 [00:00<00:00, 961.79it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 590/1024 [00:00<00:00, 961.79it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 590/1024 [00:00<00:00, 961.79it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 590/1024 [00:00<00:00, 961.79it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 590/1024 [00:00<00:00, 961.79it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 684/1024 [00:00<00:00, 954.64it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 684/1024 [00:00<00:00, 954.64it/s, reward=-0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 684/1024 [00:00<00:00, 954.64it/s, reward=-0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 684/1024 [00:00<00:00, 954.64it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 684/1024 [00:00<00:00, 954.64it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 770/1024 [00:00<00:00, 911.63it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 770/1024 [00:00<00:00, 911.63it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 770/1024 [00:00<00:00, 911.63it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 770/1024 [00:00<00:00, 911.63it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 770/1024 [00:00<00:00, 911.63it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:00<00:00, 919.79it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:00<00:00, 919.79it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:00<00:00, 919.79it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:01<00:00, 919.79it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 864/1024 [00:01<00:00, 919.79it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 957/1024 [00:01<00:00, 922.74it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 957/1024 [00:01<00:00, 922.74it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 957/1024 [00:01<00:00, 922.74it/s, reward=0.0, eps=0, p_loss=-0.049, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 1038.70it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 1038.70it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 1038.70it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 1038.70it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 1038.70it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 1006.93it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 1006.93it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 203/1024 [00:00<00:00, 1006.93it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 987.54it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 987.54it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 987.54it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 987.54it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 300/1024 [00:00<00:00, 987.54it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1024 [00:00<00:00, 980.35it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1024 [00:00<00:00, 980.35it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1024 [00:00<00:00, 980.35it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1024 [00:00<00:00, 980.35it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1024 [00:00<00:00, 980.35it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 496/1024 [00:00<00:00, 981.69it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 496/1024 [00:00<00:00, 981.69it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 496/1024 [00:00<00:00, 981.69it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 496/1024 [00:00<00:00, 981.69it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 496/1024 [00:00<00:00, 981.69it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 592/1024 [00:00<00:00, 973.13it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 592/1024 [00:00<00:00, 973.13it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 592/1024 [00:00<00:00, 973.13it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 592/1024 [00:00<00:00, 973.13it/s, reward=-0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 592/1024 [00:00<00:00, 973.13it/s, reward=-0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 688/1024 [00:00<00:00, 967.56it/s, reward=-0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 688/1024 [00:00<00:00, 967.56it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 688/1024 [00:00<00:00, 967.56it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 688/1024 [00:00<00:00, 967.56it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 688/1024 [00:00<00:00, 967.56it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 782/1024 [00:00<00:00, 957.38it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 782/1024 [00:00<00:00, 957.38it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 782/1024 [00:00<00:00, 957.38it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 782/1024 [00:00<00:00, 957.38it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 782/1024 [00:00<00:00, 957.38it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 871/1024 [00:00<00:00, 910.89it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 871/1024 [00:00<00:00, 910.89it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 871/1024 [00:00<00:00, 910.89it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 871/1024 [00:01<00:00, 910.89it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 871/1024 [00:01<00:00, 910.89it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 962/1024 [00:01<00:00, 910.26it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 962/1024 [00:01<00:00, 910.26it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 962/1024 [00:01<00:00, 910.26it/s, reward=0.0, eps=0, p_loss=-0.022, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1073.79it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1073.79it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1073.79it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1073.79it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1073.79it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1005.91it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1005.91it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1005.91it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1005.91it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–‰        | 204/1024 [00:00<00:00, 1005.91it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 301/1024 [00:00<00:00, 986.92it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 301/1024 [00:00<00:00, 986.92it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 301/1024 [00:00<00:00, 986.92it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 986.04it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 986.04it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 986.04it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 986.04it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 400/1024 [00:00<00:00, 986.04it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 497/1024 [00:00<00:00, 978.26it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 497/1024 [00:00<00:00, 978.26it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 497/1024 [00:00<00:00, 978.26it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 497/1024 [00:00<00:00, 978.26it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 497/1024 [00:00<00:00, 978.26it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 593/1024 [00:00<00:00, 971.35it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 593/1024 [00:00<00:00, 971.35it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 593/1024 [00:00<00:00, 971.35it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 593/1024 [00:00<00:00, 971.35it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 593/1024 [00:00<00:00, 971.35it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686/1024 [00:00<00:00, 957.79it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686/1024 [00:00<00:00, 957.79it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686/1024 [00:00<00:00, 957.79it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686/1024 [00:00<00:00, 957.79it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686/1024 [00:00<00:00, 957.79it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 768/1024 [00:00<00:00, 911.84it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 768/1024 [00:00<00:00, 911.84it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 768/1024 [00:00<00:00, 911.84it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 768/1024 [00:00<00:00, 911.84it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 768/1024 [00:00<00:00, 911.84it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 857/1024 [00:00<00:00, 904.68it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 857/1024 [00:00<00:00, 904.68it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 857/1024 [00:00<00:00, 904.68it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 857/1024 [00:01<00:00, 904.68it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 857/1024 [00:01<00:00, 904.68it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 951/1024 [00:01<00:00, 914.12it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 951/1024 [00:01<00:00, 914.12it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 951/1024 [00:01<00:00, 914.12it/s, reward=0.0, eps=0, p_loss=0.025, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 1003.18it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 1003.18it/s, reward=-0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  10%|â–ˆ         | 104/1024 [00:00<00:00, 1003.18it/s, reward=-0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 198/1024 [00:00<00:00, 963.57it/s, reward=-0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 198/1024 [00:00<00:00, 963.57it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 198/1024 [00:00<00:00, 963.57it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 198/1024 [00:00<00:00, 963.57it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  19%|â–ˆâ–‰        | 198/1024 [00:00<00:00, 963.57it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 296/1024 [00:00<00:00, 967.50it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 296/1024 [00:00<00:00, 967.50it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 296/1024 [00:00<00:00, 967.50it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 296/1024 [00:00<00:00, 967.50it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  29%|â–ˆâ–ˆâ–‰       | 296/1024 [00:00<00:00, 967.50it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 394/1024 [00:00<00:00, 971.73it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 394/1024 [00:00<00:00, 971.73it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 394/1024 [00:00<00:00, 971.73it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 394/1024 [00:00<00:00, 971.73it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 394/1024 [00:00<00:00, 971.73it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 492/1024 [00:00<00:00, 972.36it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 492/1024 [00:00<00:00, 972.36it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 492/1024 [00:00<00:00, 972.36it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 492/1024 [00:00<00:00, 972.36it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 492/1024 [00:00<00:00, 972.36it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 589/1024 [00:00<00:00, 968.34it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 589/1024 [00:00<00:00, 968.34it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 589/1024 [00:00<00:00, 968.34it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 589/1024 [00:00<00:00, 968.34it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 589/1024 [00:00<00:00, 968.34it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 682/1024 [00:00<00:00, 955.43it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 682/1024 [00:00<00:00, 955.43it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 682/1024 [00:00<00:00, 955.43it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 682/1024 [00:00<00:00, 955.43it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 682/1024 [00:00<00:00, 955.43it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 770/1024 [00:00<00:00, 930.40it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 770/1024 [00:00<00:00, 930.40it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 770/1024 [00:00<00:00, 930.40it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 770/1024 [00:00<00:00, 930.40it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 770/1024 [00:00<00:00, 930.40it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 856/1024 [00:00<00:00, 908.34it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 856/1024 [00:00<00:00, 908.34it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 856/1024 [00:00<00:00, 908.34it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 856/1024 [00:01<00:00, 908.34it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 856/1024 [00:01<00:00, 908.34it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 951/1024 [00:01<00:00, 920.13it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 951/1024 [00:01<00:00, 920.13it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 951/1024 [00:01<00:00, 920.13it/s, reward=0.0, eps=0, p_loss=0.030, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 968.36it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 968.36it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 968.36it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 968.36it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 968.36it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 208/1024 [00:00<00:00, 981.97it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 208/1024 [00:00<00:00, 981.97it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 208/1024 [00:00<00:00, 981.97it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 208/1024 [00:00<00:00, 981.97it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 208/1024 [00:00<00:00, 981.97it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–ˆ       | 308/1024 [00:00<00:00, 988.86it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–ˆ       | 308/1024 [00:00<00:00, 988.86it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–ˆ       | 308/1024 [00:00<00:00, 988.86it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–ˆ       | 308/1024 [00:00<00:00, 988.86it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–ˆ       | 308/1024 [00:00<00:00, 988.86it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 408/1024 [00:00<00:00, 992.85it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 408/1024 [00:00<00:00, 992.85it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 408/1024 [00:00<00:00, 992.85it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 408/1024 [00:00<00:00, 992.85it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 408/1024 [00:00<00:00, 992.85it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 507/1024 [00:00<00:00, 989.48it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 507/1024 [00:00<00:00, 989.48it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 507/1024 [00:00<00:00, 989.48it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 507/1024 [00:00<00:00, 989.48it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 507/1024 [00:00<00:00, 989.48it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 608/1024 [00:00<00:00, 995.48it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 608/1024 [00:00<00:00, 995.48it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 608/1024 [00:00<00:00, 995.48it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 608/1024 [00:00<00:00, 995.48it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 608/1024 [00:00<00:00, 995.48it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 704/1024 [00:00<00:00, 982.70it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 704/1024 [00:00<00:00, 982.70it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 704/1024 [00:00<00:00, 982.70it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 704/1024 [00:00<00:00, 982.70it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 704/1024 [00:00<00:00, 982.70it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 801/1024 [00:00<00:00, 977.30it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 801/1024 [00:00<00:00, 977.30it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 801/1024 [00:00<00:00, 977.30it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 897/1024 [00:00<00:00, 970.77it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 897/1024 [00:00<00:00, 970.77it/s, reward=-0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 897/1024 [00:00<00:00, 970.77it/s, reward=-0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 897/1024 [00:00<00:00, 970.77it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 897/1024 [00:00<00:00, 970.77it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 993/1024 [00:01<00:00, 965.52it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 993/1024 [00:01<00:00, 965.52it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 993/1024 [00:01<00:00, 965.52it/s, reward=0.0, eps=0, p_loss=0.016, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=0%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=-0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=5%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1075.55it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=10%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1075.55it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1075.55it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=15%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1075.55it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  11%|â–ˆ         | 108/1024 [00:00<00:00, 1075.55it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 208/1024 [00:00<00:00, 1029.09it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=20%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 208/1024 [00:00<00:00, 1029.09it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 208/1024 [00:00<00:00, 1029.09it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=25%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 208/1024 [00:00<00:00, 1029.09it/s, reward=-0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  20%|â–ˆâ–ˆ        | 208/1024 [00:00<00:00, 1029.09it/s, reward=-0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–ˆ       | 308/1024 [00:00<00:00, 1013.33it/s, reward=-0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=29%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–ˆ       | 308/1024 [00:00<00:00, 1013.33it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–ˆ       | 308/1024 [00:00<00:00, 1013.33it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=34%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–ˆ       | 308/1024 [00:00<00:00, 1013.33it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  30%|â–ˆâ–ˆâ–ˆ       | 308/1024 [00:00<00:00, 1013.33it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 409/1024 [00:00<00:00, 1011.88it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=39%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 409/1024 [00:00<00:00, 1011.88it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 409/1024 [00:00<00:00, 1011.88it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=44%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 409/1024 [00:00<00:00, 1011.88it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 409/1024 [00:00<00:00, 1011.88it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 507/1024 [00:00<00:00, 1000.30it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=49%]
[TRAINING] ğŸ¯ Collecting Trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 507/1024 [00:00<00:00, 1000.30it/s, reward=-0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 507/1024 [00:00<00:00, 1000.30it/s, reward=-0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=54%]
[TRAINING] ğŸ¯ Collecting Trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 507/1024 [00:00<00:00, 1000.30it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 507/1024 [00:00<00:00, 1000.30it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 606/1024 [00:00<00:00, 994.13it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=59%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 606/1024 [00:00<00:00, 994.13it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 606/1024 [00:00<00:00, 994.13it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=64%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 606/1024 [00:00<00:00, 994.13it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 606/1024 [00:00<00:00, 994.13it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 705/1024 [00:00<00:00, 991.54it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=68%]
[TRAINING] ğŸ¯ Collecting Trajectories:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 705/1024 [00:00<00:00, 991.54it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 705/1024 [00:00<00:00, 991.54it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=73%]
[TRAINING] ğŸ¯ Collecting Trajectories:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 705/1024 [00:00<00:00, 991.54it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 705/1024 [00:00<00:00, 991.54it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 801/1024 [00:00<00:00, 980.21it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=78%]
[TRAINING] ğŸ¯ Collecting Trajectories:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 801/1024 [00:00<00:00, 980.21it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 801/1024 [00:00<00:00, 980.21it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 897/1024 [00:00<00:00, 972.27it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=83%]
[TRAINING] ğŸ¯ Collecting Trajectories:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 897/1024 [00:00<00:00, 972.27it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 897/1024 [00:00<00:00, 972.27it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=88%]
[TRAINING] ğŸ¯ Collecting Trajectories:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 897/1024 [00:00<00:00, 972.27it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 897/1024 [00:00<00:00, 972.27it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 991/1024 [00:01<00:00, 961.81it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=93%]
[TRAINING] ğŸ¯ Collecting Trajectories:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 991/1024 [00:01<00:00, 961.81it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=98%]
[TRAINING] ğŸ¯ Collecting Trajectories:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 991/1024 [00:01<00:00, 961.81it/s, reward=0.0, eps=0, p_loss=0.026, v_loss=0.000, progress=98%]
[TRAINING] 
[TRAINING] 
[TRAINING] ğŸ¯ Collecting Trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]
[TRAINING] ğŸ¯ Collect