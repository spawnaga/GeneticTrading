/home/runner/workspace/main.py:28: UserWarning: cudf import failed (No module named 'cudf'); falling back to pandas (no GPU).
  warnings.warn(f"cudf import failed ({e}); falling back to pandas (no GPU).")
WARNING:root:Distributed training not available, running in single-process mode
2025-06-25 02:58:20 [INFO    ] [Rank-6838] STARTUP        : ================================================================================
2025-06-25 02:58:20 [INFO    ] [Rank-6838] STARTUP        : Training session started for rank 0
2025-06-25 02:58:20 [INFO    ] [Rank-6838] STARTUP        : Log file: logs/training_rank_0.log
2025-06-25 02:58:20 [INFO    ] [Rank-6838] STARTUP        : Process ID: 6838
2025-06-25 02:58:20 [INFO    ] [Rank-6838] STARTUP        : Working directory: /home/runner/workspace
2025-06-25 02:58:20 [INFO    ] [Rank-6838] STARTUP        : ================================================================================
2025-06-25 02:58:20 [INFO    ] [Rank-6838] root           : NCCL_TIMEOUT = 1800000 ms
2025-06-25 02:58:20 [INFO    ] [Rank-6838] root           : Using 100.0% of available data
2025-06-25 02:58:20 [INFO    ] [Rank-6838] root           : Models will be saved to: ./models
2025-06-25 02:58:20 [INFO    ] [Rank-6838] root           : Rank 0/1 starting on cpu (has_cudf=False)
2025-06-25 02:58:20 [INFO    ] [Rank-6838] root           : Parquet cache found; skipping preprocessing.
2025-06-25 02:58:20 [INFO    ] [Rank-6838] root           : Total data: 4000 train, 1000 test rows
[GA] Loaded GA model from models/ga_models/ga_policy_model.pth
2025-06-25 02:58:20 [INFO    ] [Rank-6838] root           : Successfully loaded GA model from models/ga_models/ga_policy_model.pth
2025-06-25 02:58:20 [INFO    ] [Rank-6838] root           : GA Eval → CAGR: -127467328.2595, Sharpe: -2836.9051, MDD: 33950.5422
2025-06-25 02:58:20 [WARNING ] [Rank-6838] policy_gradient_methods: Dimension mismatch: saved model expects 25, current model has 116
2025-06-25 02:58:20 [INFO    ] [Rank-6838] policy_gradient_methods: Starting from scratch due to incompatible checkpoint at models/ppo_models/ppo_model.pth
I0625 02:58:21.441000 6838 .pythonlibs/lib/python3.12/site-packages/torch/distributed/nn/jit/instantiator.py:24] Created a temporary directory at /tmp/tmp02wwzhxv
I0625 02:58:21.442000 6838 .pythonlibs/lib/python3.12/site-packages/torch/distributed/nn/jit/instantiator.py:75] Writing /tmp/tmp02wwzhxv/_remote_module_non_scriptable.py
Removed old TensorBoard run: ./runs/ppo_rank_0
2025-06-25 02:58:22 [WARNING ] [Rank-6838] root           : Could not load PPO checkpoint (Error(s) in loading state_dict for ActorCriticNet:
    size mismatch for base.0.weight: copying a param with shape torch.Size([64, 25]) from checkpoint, the shape in current model is torch.Size([64, 116]).)! Starting from scratch.
2025-06-25 02:58:22 [INFO    ] [Rank-6838] policy_gradient_methods: Starting training: updates 0 → 975
PPO updates:   0%|                                                                                                                                                                   | 0/976 [00:00<?, ?it/s]2025-06-25 02:58:24 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 02:58:24.069671
PPO updates:   1%|█▎                                                                                                                                | 10/976 [00:09<16:06,  1.00s/it, total_reward=4049.7300]2025-06-25 02:58:32 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 02:58:32.972018
PPO updates:   2%|██▋                                                                                                                               | 20/976 [00:21<16:47,  1.05s/it, total_reward=7134.2471]2025-06-25 02:58:44 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 02:58:44.552454
PPO updates:   3%|███▉                                                                                                                              | 30/976 [00:29<14:06,  1.12it/s, total_reward=3494.2222]2025-06-25 02:58:52 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 02:58:52.595716
PPO updates:   4%|█████▎                                                                                                                           | 40/976 [00:37<13:06,  1.19it/s, total_reward=-4876.5132]2025-06-25 02:59:00 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 02:59:00.648740
PPO updates:   5%|██████▋                                                                                                                            | 50/976 [00:47<16:22,  1.06s/it, total_reward=350.2679]2025-06-25 02:59:12 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 02:59:12.537324
PPO updates:   6%|███████▉                                                                                                                         | 60/976 [00:57<13:02,  1.17it/s, total_reward=-6644.7949]2025-06-25 02:59:20 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 02:59:20.531532
PPO updates:   7%|█████████▎                                                                                                                        | 70/976 [01:05<12:17,  1.23it/s, total_reward=7602.7422]2025-06-25 02:59:28 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 02:59:28.203648
PPO updates:   8%|██████████▋                                                                                                                       | 80/976 [01:13<12:52,  1.16it/s, total_reward=7197.2266]2025-06-25 02:59:36 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 02:59:36.088894
PPO updates:   9%|███████████▉                                                                                                                     | 90/976 [01:20<12:28,  1.18it/s, total_reward=-9954.6621]2025-06-25 02:59:43 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 02:59:43.919551
PPO updates:  10%|█████████████                                                                                                                   | 100/976 [01:28<11:54,  1.23it/s, total_reward=-7691.3516]2025-06-25 02:59:53 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 02:59:53.304524
PPO updates:  11%|██████████████▍                                                                                                                 | 110/976 [01:38<12:48,  1.13it/s, total_reward=-9643.1455]2025-06-25 03:00:01 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 03:00:01.375807
PPO updates:  12%|███████████████▋                                                                                                                | 120/976 [01:46<12:29,  1.14it/s, total_reward=-9832.7305]2025-06-25 03:00:09 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 03:00:09.400320
PPO updates:  13%|█████████████████                                                                                                               | 130/976 [01:54<12:03,  1.17it/s, total_reward=-9254.6484]2025-06-25 03:00:17 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 03:00:17.637647
PPO updates:  14%|██████████████████▌                                                                                                              | 140/976 [02:04<16:29,  1.18s/it, total_reward=1378.4658]2025-06-25 03:00:27 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 03:00:27.711097
PPO updates:  15%|███████████████████▋                                                                                                            | 150/976 [02:12<12:40,  1.09it/s, total_reward=-9029.1973]2025-06-25 03:00:37 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 03:00:37.783315
PPO updates:  16%|█████████████████████▏                                                                                                           | 160/976 [02:23<12:33,  1.08it/s, total_reward=7811.0986]2025-06-25 03:00:45 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 03:00:45.969263
PPO updates:  17%|██████████████████████▎                                                                                                         | 170/976 [02:31<13:08,  1.02it/s, total_reward=-5977.1592]2025-06-25 03:00:54 [INFO    ] [Rank-6838] policy_gradient_methods: Saved model to models/ppo_models/ppo_model.pth at 2025-06-25 03:00:54.411021
PPO updates:  18%|███████████████████████▍                                                                                                        | 179/976 [02:40<13:09,  1.01it/s, total_reward=-7659.0464]