(GeneticTrading) alex@alex-System-Product-Name:/mnt/windows/GeneticTrading$ source fix_cuda_env.sh && torchrun --nproc_per_node=4 --nnodes=1 --node_rank=0 --master_addr=127.0.0.1 --master_port=12355 main.py --max-rows 0 --data-percentage 1.0 --models-dir ./models/4gpu_production --total-steps 5000000 --nccl-timeout 7200000
üîß Fixing CUDA Environment Issues...
üìã Checking NVIDIA driver...
Running nvidia-smi...
Tue Jun 24 23:50:30 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3090        On  | 00000000:01:00.0  On |                  N/A |
| 44%   51C    P8              26W / 350W |    219MiB / 24576MiB |     15%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce RTX 3090        On  | 00000000:05:00.0 Off |                  N/A |
|  0%   50C    P8              19W / 350W |     10MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce RTX 3090        On  | 00000000:08:00.0 Off |                  N/A |
| 44%   54C    P8              23W / 350W |     10MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce RTX 3090        On  | 00000000:09:00.0 Off |                  N/A |
|  0%   55C    P8              14W / 350W |     10MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      3332      G   /usr/lib/xorg/Xorg                           87MiB |
|    0   N/A  N/A      3573      G   /usr/bin/gnome-shell                        122MiB |
|    1   N/A  N/A      3332      G   /usr/lib/xorg/Xorg                            4MiB |
|    2   N/A  N/A      3332      G   /usr/lib/xorg/Xorg                            4MiB |
|    3   N/A  N/A      3332      G   /usr/lib/xorg/Xorg                            4MiB |
+---------------------------------------------------------------------------------------+
‚úÖ NVIDIA driver found and working
üìã Searching for CUDA libraries...
‚úÖ Found libcuda.so.1 at: /usr/lib/x86_64-linux-gnu/libcuda.so.1
üìù Creating environment setup script...
üìù Creating CPU-only environment setup script...
‚úÖ Created setup_cuda_env.sh
‚úÖ Created setup_cpu_env.sh

üöÄ Next steps:
For GPU training:
1. Run: source setup_cuda_env.sh
2. Run: python run_4gpu_1000rows.py

For CPU-only training:
1. Run: source setup_cpu_env.sh
2. Run: python run_4gpu_1000rows.py
W0624 23:50:32.320000 4913 site-packages/torch/distributed/run.py:766] 
W0624 23:50:32.320000 4913 site-packages/torch/distributed/run.py:766] *****************************************
W0624 23:50:32.320000 4913 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0624 23:50:32.320000 4913 site-packages/torch/distributed/run.py:766] *****************************************
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/mnt/windows/GeneticTrading/main.py", line 61, in <module>
  File "/mnt/windows/GeneticTrading/main.py", line 61, in <module>
  File "/mnt/windows/GeneticTrading/main.py", line 61, in <module>
  File "/mnt/windows/GeneticTrading/main.py", line 61, in <module>
        from data_preprocessing import create_environment_data    
from data_preprocessing import create_environment_datafrom data_preprocessing import create_environment_data    
from data_preprocessing import create_environment_data

  File "/mnt/windows/GeneticTrading/data_preprocessing.py", line 28, in <module>
  File "/mnt/windows/GeneticTrading/data_preprocessing.py", line 28, in <module>
  File "/mnt/windows/GeneticTrading/data_preprocessing.py", line 28, in <module>
  File "/mnt/windows/GeneticTrading/data_preprocessing.py", line 28, in <module>
        logger.info(f"GPU processing enabled with {torch.cuda.device_count()} GPUs")    logger.info(f"GPU processing enabled with {torch.cuda.device_count()} GPUs")
logger.info(f"GPU processing enabled with {torch.cuda.device_count()} GPUs")

    logger.info(f"GPU processing enabled with {torch.cuda.device_count()} GPUs")
          ^   ^ ^ ^ ^^^^^^^^^^^^^^
^^^^
^^NameError

: NameErrorname 'logger' is not defined: NameErrorname 'logger' is not definedNameError: : name 'logger' is not definedname 'logger' is not defined



W0624 23:50:37.233000 4913 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 4966 closing signal SIGTERM
E0624 23:50:37.235000 4913 site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 1 (pid: 4967) of binary: /home/alex/miniconda3/envs/GeneticTrading/bin/python3.12
Traceback (most recent call last):
  File "/home/alex/miniconda3/envs/GeneticTrading/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alex/miniconda3/envs/GeneticTrading/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/alex/miniconda3/envs/GeneticTrading/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in main
    run(args)
  File "/home/alex/miniconda3/envs/GeneticTrading/lib/python3.12/site-packages/torch/distributed/run.py", line 883, in run
    elastic_launch(
  File "/home/alex/miniconda3/envs/GeneticTrading/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alex/miniconda3/envs/GeneticTrading/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 270, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-06-24_23:50:37
  host      : alex-System-Product-Name
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 4968)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-06-24_23:50:37
  host      : alex-System-Product-Name
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 4969)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-06-24_23:50:37
  host      : alex-System-Product-Name
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 4967)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
(GeneticTrading) alex@alex-System-Product-Name:/mnt/windows/GeneticTrading$ source fix_cuda_env.sh && torchrun --nproc_per_node=4 --nnodes=1 --node_rank=0 --master_addr=127.0.0.1 --master_port=12355 main.py --max-rows 0 --data-percentage 1.0 --models-dir ./models/4gpu_production --total-steps 5000000 --nccl-timeout 7200000
üîß Fixing CUDA Environment Issues...
üìã Checking NVIDIA driver...
Running nvidia-smi...
Tue Jun 24 23:52:12 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3090        On  | 00000000:01:00.0  On |                  N/A |
|  0%   48C    P8              26W / 350W |    237MiB / 24576MiB |     10%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce RTX 3090        On  | 00000000:05:00.0 Off |                  N/A |
|  0%   50C    P8              18W / 350W |     10MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce RTX 3090        On  | 00000000:08:00.0 Off |                  N/A |
| 44%   51C    P8              20W / 350W |     10MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce RTX 3090        On  | 00000000:09:00.0 Off |                  N/A |
|  0%   54C    P8              25W / 350W |     10MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      3332      G   /usr/lib/xorg/Xorg                           97MiB |
|    0   N/A  N/A      3573      G   /usr/bin/gnome-shell                        130MiB |
|    1   N/A  N/A      3332      G   /usr/lib/xorg/Xorg                            4MiB |
|    2   N/A  N/A      3332      G   /usr/lib/xorg/Xorg                            4MiB |
|    3   N/A  N/A      3332      G   /usr/lib/xorg/Xorg                            4MiB |
+---------------------------------------------------------------------------------------+
‚úÖ NVIDIA driver found and working
üìã Searching for CUDA libraries...
‚úÖ Found libcuda.so.1 at: /usr/lib/x86_64-linux-gnu/libcuda.so.1
üìù Creating environment setup script...
üìù Creating CPU-only environment setup script...
‚úÖ Created setup_cuda_env.sh
‚úÖ Created setup_cpu_env.sh

üöÄ Next steps:
For GPU training:
1. Run: source setup_cuda_env.sh
2. Run: python run_4gpu_1000rows.py

For CPU-only training:
1. Run: source setup_cpu_env.sh
2. Run: python run_4gpu_1000rows.py
W0624 23:52:13.426000 5213 site-packages/torch/distributed/run.py:766] 
W0624 23:52:13.426000 5213 site-packages/torch/distributed/run.py:766] *****************************************
W0624 23:52:13.426000 5213 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0624 23:52:13.426000 5213 site-packages/torch/distributed/run.py:766] *****************************************
I0624 23:52:15.613000 5247 site-packages/torch/distributed/distributed_c10d.py:432] Using backend config: {'cuda': 'nccl'}
2025-06-24 23:52:15 [INFO    ] [Rank-5247] STARTUP             : ================================================================================
2025-06-24 23:52:15 [INFO    ] [Rank-5247] STARTUP             : Training session started for rank 0
2025-06-24 23:52:15 [INFO    ] [Rank-5247] STARTUP             : Log file: logs/training_rank_0.log
2025-06-24 23:52:15 [INFO    ] [Rank-5247] STARTUP             : Process ID: 5247
2025-06-24 23:52:15 [INFO    ] [Rank-5247] STARTUP             : Working directory: /mnt/windows/GeneticTrading
2025-06-24 23:52:15 [INFO    ] [Rank-5247] STARTUP             : ================================================================================
2025-06-24 23:52:15 [INFO    ] [Rank-5247] root                : NCCL_TIMEOUT = 7200000 ms
2025-06-24 23:52:15 [INFO    ] [Rank-5247] root                : Using 100.0% of available data
2025-06-24 23:52:15 [INFO    ] [Rank-5247] root                : Models will be saved to: ./models/4gpu_production
2025-06-24 23:52:15 [INFO    ] [Rank-5247] root                : Rank 0/4 starting on cuda:0 (has_cudf=True)
2025-06-24 23:52:15 [INFO    ] [Rank-5247] root                : Processing data with max_rows=None, chunk_size=500000
2025-06-24 23:52:15 [INFO    ] [Rank-5247] data_preprocessing  : Loading cached dataset from ./cached_data/combined_c45aa0ea65a985db5a05afa4579f0ae232581f54055da961dfa91464108f8fc3.parquet
I0624 23:52:15.798000 5250 site-packages/torch/distributed/distributed_c10d.py:432] Using backend config: {'cuda': 'nccl'}
I0624 23:52:15.798000 5248 site-packages/torch/distributed/distributed_c10d.py:432] Using backend config: {'cuda': 'nccl'}
I0624 23:52:15.798000 5249 site-packages/torch/distributed/distributed_c10d.py:432] Using backend config: {'cuda': 'nccl'}
2025-06-24 23:52:15 [INFO    ] [Rank-5250] STARTUP             : ================================================================================
2025-06-24 23:52:15 [INFO    ] [Rank-5250] STARTUP             : Training session started for rank 3
2025-06-24 23:52:15 [INFO    ] [Rank-5250] STARTUP             : Log file: logs/training_rank_3.log
2025-06-24 23:52:15 [INFO    ] [Rank-5250] STARTUP             : Process ID: 5250
2025-06-24 23:52:15 [INFO    ] [Rank-5250] STARTUP             : Working directory: /mnt/windows/GeneticTrading
2025-06-24 23:52:15 [INFO    ] [Rank-5250] STARTUP             : ================================================================================
2025-06-24 23:52:15 [INFO    ] [Rank-5248] STARTUP             : ================================================================================
2025-06-24 23:52:15 [INFO    ] [Rank-5250] root                : Rank 3/4 starting on cuda:3 (has_cudf=True)
2025-06-24 23:52:15 [INFO    ] [Rank-5248] STARTUP             : Training session started for rank 1
2025-06-24 23:52:15 [INFO    ] [Rank-5248] STARTUP             : Log file: logs/training_rank_1.log
2025-06-24 23:52:15 [INFO    ] [Rank-5248] STARTUP             : Process ID: 5248
2025-06-24 23:52:15 [INFO    ] [Rank-5248] STARTUP             : Working directory: /mnt/windows/GeneticTrading
2025-06-24 23:52:15 [INFO    ] [Rank-5248] STARTUP             : ================================================================================
2025-06-24 23:52:15 [INFO    ] [Rank-5248] root                : Rank 1/4 starting on cuda:1 (has_cudf=True)
2025-06-24 23:52:15 [INFO    ] [Rank-5249] STARTUP             : ================================================================================
2025-06-24 23:52:15 [INFO    ] [Rank-5249] STARTUP             : Training session started for rank 2
2025-06-24 23:52:15 [INFO    ] [Rank-5249] STARTUP             : Log file: logs/training_rank_2.log
2025-06-24 23:52:15 [INFO    ] [Rank-5249] STARTUP             : Process ID: 5249
2025-06-24 23:52:15 [INFO    ] [Rank-5249] STARTUP             : Working directory: /mnt/windows/GeneticTrading
2025-06-24 23:52:15 [INFO    ] [Rank-5249] STARTUP             : ================================================================================
2025-06-24 23:52:15 [INFO    ] [Rank-5249] root                : Rank 2/4 starting on cuda:2 (has_cudf=True)
2025-06-24 23:52:16 [INFO    ] [Rank-5247] data_preprocessing  : Processing 5389750 rows in chunks of 500000
2025-06-24 23:52:16 [INFO    ] [Rank-5247] data_preprocessing  : Processing chunk 1/11
2025-06-24 23:52:16 [INFO    ] [Rank-5247] numba.cuda.cudadrv.driver: init
2025-06-24 23:52:16 [INFO    ] [Rank-5247] data_preprocessing  : Processing chunk 2/11
2025-06-24 23:52:16 [INFO    ] [Rank-5247] data_preprocessing  : Processing chunk 3/11
2025-06-24 23:52:16 [INFO    ] [Rank-5247] data_preprocessing  : Processing chunk 4/11
2025-06-24 23:52:16 [INFO    ] [Rank-5247] data_preprocessing  : Processing chunk 5/11
2025-06-24 23:52:16 [INFO    ] [Rank-5247] data_preprocessing  : Processing chunk 6/11
2025-06-24 23:52:16 [INFO    ] [Rank-5247] data_preprocessing  : Processing chunk 7/11
2025-06-24 23:52:17 [INFO    ] [Rank-5247] data_preprocessing  : Processing chunk 8/11
2025-06-24 23:52:17 [INFO    ] [Rank-5247] data_preprocessing  : Processing chunk 9/11
2025-06-24 23:52:17 [INFO    ] [Rank-5247] data_preprocessing  : Processing chunk 10/11
2025-06-24 23:52:17 [INFO    ] [Rank-5247] data_preprocessing  : Processing chunk 11/11
2025-06-24 23:52:17 [INFO    ] [Rank-5247] root                : Saving processed data to compressed Parquet...
2025-06-24 23:52:17 [INFO    ] [Rank-5247] root                : Data cached to Parquet and artifacts saved.
2025-06-24 23:52:17 [INFO    ] [Rank-5247] root                : Total data: 4311800 train, 1077950 test rows
2025-06-24 23:52:17 [INFO    ] [Rank-5247] root                : Rank 0: Sampled 100000 train rows from 4311800 total
2025-06-24 23:52:17 [INFO    ] [Rank-5247] root                : Rank 0: Sampled 20000 test rows from 1077950 total
2025-06-24 23:52:17 [INFO    ] [Rank-5248] root                : Total data: 4311800 train, 1077950 test rows
2025-06-24 23:52:17 [INFO    ] [Rank-5250] root                : Total data: 4311800 train, 1077950 test rows
2025-06-24 23:52:17 [INFO    ] [Rank-5248] root                : Rank 1: Sampled 100000 train rows from 4311800 total
2025-06-24 23:52:17 [INFO    ] [Rank-5248] root                : Rank 1: Sampled 20000 test rows from 1077950 total
2025-06-24 23:52:17 [INFO    ] [Rank-5248] numba.cuda.cudadrv.driver: init
2025-06-24 23:52:17 [INFO    ] [Rank-5250] root                : Rank 3: Sampled 100000 train rows from 4311800 total
2025-06-24 23:52:17 [INFO    ] [Rank-5250] root                : Rank 3: Sampled 20000 test rows from 1077950 total
2025-06-24 23:52:17 [INFO    ] [Rank-5250] numba.cuda.cudadrv.driver: init
2025-06-24 23:52:17 [INFO    ] [Rank-5249] root                : Total data: 4311800 train, 1077950 test rows
2025-06-24 23:52:17 [INFO    ] [Rank-5249] root                : Rank 2: Sampled 100000 train rows from 4311800 total
2025-06-24 23:52:18 [INFO    ] [Rank-5249] root                : Rank 2: Sampled 20000 test rows from 1077950 total
2025-06-24 23:52:18 [INFO    ] [Rank-5249] numba.cuda.cudadrv.driver: init
2025-06-24 23:52:19 [INFO    ] [Rank-5247] adaptive_trainer    : Starting adaptive training
2025-06-24 23:52:19 [INFO    ] [Rank-5247] adaptive_trainer    : 
=== Adaptive Training Iteration 1/20 ===
2025-06-24 23:52:19 [INFO    ] [Rank-5248] root                : Non-rank 0 process waiting for adaptive training to complete
2025-06-24 23:52:19 [INFO    ] [Rank-5250] root                : Non-rank 0 process waiting for adaptive training to complete
[rank0]: Traceback (most recent call last):
[rank0]:   File "/mnt/windows/GeneticTrading/main.py", line 487, in <module>
[rank0]:     main()
[rank0]:   File "/mnt/windows/GeneticTrading/main.py", line 446, in main
[rank0]:     training_log = adaptive_trainer.adaptive_train(
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/mnt/windows/GeneticTrading/adaptive_trainer.py", line 358, in adaptive_train
[rank0]:     performance, entropy, metrics = self.evaluate_current_policy()
[rank0]:                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/mnt/windows/GeneticTrading/adaptive_trainer.py", line 151, in evaluate_current_policy
[rank0]:     profits, times = evaluate_agent_distributed(self.test_env, agent, self.local_rank)
[rank0]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/mnt/windows/GeneticTrading/utils.py", line 303, in evaluate_agent_distributed
[rank0]:     step_result = env.step(action)
[rank0]:                   ^^^^^^^^^^^^^^^^
[rank0]:   File "/mnt/windows/GeneticTrading/futures_env.py", line 215, in step
[rank0]:     self._handle_buy(next_state)
[rank0]:   File "/mnt/windows/GeneticTrading/futures_env.py", line 255, in _handle_buy
[rank0]:     filled_price = self._simulate_fill(state.open_price, 1)
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/mnt/windows/GeneticTrading/futures_env.py", line 373, in _simulate_fill
[rank0]:     return round_to_nearest_increment(raw_price, self.tick_size)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/mnt/windows/GeneticTrading/utils.py", line 97, in round_to_nearest_increment
[rank0]:     return round(value / increment) * increment
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]: ValueError: cannot convert float NaN to integer
2025-06-24 23:52:19 [INFO    ] [Rank-5249] root                : Non-rank 0 process waiting for adaptive training to complete
[rank0]:[W624 23:52:19.015534402 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
