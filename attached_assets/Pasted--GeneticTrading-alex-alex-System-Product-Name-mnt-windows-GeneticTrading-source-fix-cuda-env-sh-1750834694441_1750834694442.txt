(GeneticTrading) alex@alex-System-Product-Name:/mnt/windows/GeneticTrading$ $ source fix_cuda_env.sh && torchrun --nproc_per_node=4 --nnodes=1 --node_rank=0 --master_addr=127.0.0.1 --master_port=12355 main.py --max-rows 0 --data-percentage 1.0 --models-dir ./models/4gpu_production --total-steps 5000000 --nccl-timeout 7200000
$: command not found
(GeneticTrading) alex@alex-System-Product-Name:/mnt/windows/GeneticTrading$ $ source fix_cuda_env.sh && torchrun --nproc_per_node=4 --nnodes=1 --node_rank=0 --master_addr=127.0.0.1 --master_port=12355 main.py --max-rows 0 --data-percentage 1.0 --models-dir ./models/4gpu_production --total-steps 5000000 --nccl-timeout 7200000
$: command not found
(GeneticTrading) alex@alex-System-Product-Name:/mnt/windows/GeneticTrading$ source fix_cuda_env.sh && torchrun --nproc_per_node=4 --nnodes=1 --node_rank=0 --master_addr=127.0.0.1 --master_port=12355 main.py --max-rows 0 --data-percentage 1.0 --models-dir ./models/4gpu_production --total-steps 5000000 --nccl-timeout 7200000
üîß Fixing CUDA Environment Issues...
üìã Checking NVIDIA driver...
Running nvidia-smi...
Tue Jun 24 23:56:54 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.247.01             Driver Version: 535.247.01   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3090        On  | 00000000:01:00.0  On |                  N/A |
|  0%   49C    P5              31W / 350W |    196MiB / 24576MiB |     12%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce RTX 3090        On  | 00000000:05:00.0 Off |                  N/A |
|  0%   49C    P8              19W / 350W |     10MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce RTX 3090        On  | 00000000:08:00.0 Off |                  N/A |
| 49%   54C    P8              21W / 350W |     10MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce RTX 3090        On  | 00000000:09:00.0 Off |                  N/A |
| 50%   57C    P8              26W / 350W |     10MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      3332      G   /usr/lib/xorg/Xorg                           92MiB |
|    0   N/A  N/A      3573      G   /usr/bin/gnome-shell                         95MiB |
|    1   N/A  N/A      3332      G   /usr/lib/xorg/Xorg                            4MiB |
|    2   N/A  N/A      3332      G   /usr/lib/xorg/Xorg                            4MiB |
|    3   N/A  N/A      3332      G   /usr/lib/xorg/Xorg                            4MiB |
+---------------------------------------------------------------------------------------+
‚úÖ NVIDIA driver found and working
üìã Searching for CUDA libraries...
‚úÖ Found libcuda.so.1 at: /usr/lib/x86_64-linux-gnu/libcuda.so.1
üìù Creating environment setup script...
üìù Creating CPU-only environment setup script...
‚úÖ Created setup_cuda_env.sh
‚úÖ Created setup_cpu_env.sh

üöÄ Next steps:
For GPU training:
1. Run: source setup_cuda_env.sh
2. Run: python run_4gpu_1000rows.py

For CPU-only training:
1. Run: source setup_cpu_env.sh
2. Run: python run_4gpu_1000rows.py
W0624 23:56:55.594000 6995 site-packages/torch/distributed/run.py:766] 
W0624 23:56:55.594000 6995 site-packages/torch/distributed/run.py:766] *****************************************
W0624 23:56:55.594000 6995 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0624 23:56:55.594000 6995 site-packages/torch/distributed/run.py:766] *****************************************
I0624 23:56:57.585000 7028 site-packages/torch/distributed/distributed_c10d.py:432] Using backend config: {'cuda': 'nccl'}
2025-06-24 23:56:57 [INFO    ] [Rank-7028] STARTUP             : ================================================================================
2025-06-24 23:56:57 [INFO    ] [Rank-7028] STARTUP             : Training session started for rank 0
2025-06-24 23:56:57 [INFO    ] [Rank-7028] STARTUP             : Log file: logs/training_rank_0.log
2025-06-24 23:56:57 [INFO    ] [Rank-7028] STARTUP             : Process ID: 7028
2025-06-24 23:56:57 [INFO    ] [Rank-7028] STARTUP             : Working directory: /mnt/windows/GeneticTrading
2025-06-24 23:56:57 [INFO    ] [Rank-7028] STARTUP             : ================================================================================
2025-06-24 23:56:57 [INFO    ] [Rank-7028] root                : NCCL_TIMEOUT = 7200000 ms
2025-06-24 23:56:57 [INFO    ] [Rank-7028] root                : Using 100.0% of available data
2025-06-24 23:56:57 [INFO    ] [Rank-7028] root                : Models will be saved to: ./models/4gpu_production
2025-06-24 23:56:57 [INFO    ] [Rank-7028] root                : Rank 0/4 starting on cuda:0 (has_cudf=True)
2025-06-24 23:56:57 [INFO    ] [Rank-7028] root                : Parquet cache found; skipping preprocessing.
I0624 23:56:57.752000 7031 site-packages/torch/distributed/distributed_c10d.py:432] Using backend config: {'cuda': 'nccl'}
2025-06-24 23:56:57 [INFO    ] [Rank-7031] STARTUP             : ================================================================================
2025-06-24 23:56:57 [INFO    ] [Rank-7031] STARTUP             : Training session started for rank 3
2025-06-24 23:56:57 [INFO    ] [Rank-7031] STARTUP             : Log file: logs/training_rank_3.log
2025-06-24 23:56:57 [INFO    ] [Rank-7031] STARTUP             : Process ID: 7031
2025-06-24 23:56:57 [INFO    ] [Rank-7031] STARTUP             : Working directory: /mnt/windows/GeneticTrading
2025-06-24 23:56:57 [INFO    ] [Rank-7031] STARTUP             : ================================================================================
2025-06-24 23:56:57 [INFO    ] [Rank-7031] root                : Rank 3/4 starting on cuda:3 (has_cudf=True)
I0624 23:56:57.764000 7029 site-packages/torch/distributed/distributed_c10d.py:432] Using backend config: {'cuda': 'nccl'}
2025-06-24 23:56:57 [INFO    ] [Rank-7029] STARTUP             : ================================================================================
2025-06-24 23:56:57 [INFO    ] [Rank-7029] STARTUP             : Training session started for rank 1
2025-06-24 23:56:57 [INFO    ] [Rank-7029] STARTUP             : Log file: logs/training_rank_1.log
2025-06-24 23:56:57 [INFO    ] [Rank-7029] STARTUP             : Process ID: 7029
2025-06-24 23:56:57 [INFO    ] [Rank-7029] STARTUP             : Working directory: /mnt/windows/GeneticTrading
2025-06-24 23:56:57 [INFO    ] [Rank-7029] STARTUP             : ================================================================================
2025-06-24 23:56:57 [INFO    ] [Rank-7029] root                : Rank 1/4 starting on cuda:1 (has_cudf=True)
I0624 23:56:57.769000 7030 site-packages/torch/distributed/distributed_c10d.py:432] Using backend config: {'cuda': 'nccl'}
2025-06-24 23:56:57 [INFO    ] [Rank-7030] STARTUP             : ================================================================================
2025-06-24 23:56:57 [INFO    ] [Rank-7030] STARTUP             : Training session started for rank 2
2025-06-24 23:56:57 [INFO    ] [Rank-7030] STARTUP             : Log file: logs/training_rank_2.log
2025-06-24 23:56:57 [INFO    ] [Rank-7030] STARTUP             : Process ID: 7030
2025-06-24 23:56:57 [INFO    ] [Rank-7030] STARTUP             : Working directory: /mnt/windows/GeneticTrading
2025-06-24 23:56:57 [INFO    ] [Rank-7030] STARTUP             : ================================================================================
2025-06-24 23:56:57 [INFO    ] [Rank-7030] root                : Rank 2/4 starting on cuda:2 (has_cudf=True)
2025-06-24 23:56:58 [INFO    ] [Rank-7028] root                : Total data: 4311800 train, 1077950 test rows
2025-06-24 23:56:58 [INFO    ] [Rank-7031] root                : Total data: 4311800 train, 1077950 test rows
2025-06-24 23:56:58 [INFO    ] [Rank-7029] root                : Total data: 4311800 train, 1077950 test rows
2025-06-24 23:56:58 [INFO    ] [Rank-7031] root                : Rank 3: Sampled 100000 train rows from 4311800 total
2025-06-24 23:56:58 [INFO    ] [Rank-7028] root                : Rank 0: Sampled 100000 train rows from 4311800 total
2025-06-24 23:56:58 [INFO    ] [Rank-7029] root                : Rank 1: Sampled 100000 train rows from 4311800 total
2025-06-24 23:56:58 [INFO    ] [Rank-7028] root                : Rank 0: Sampled 20000 test rows from 1077950 total
2025-06-24 23:56:58 [INFO    ] [Rank-7031] root                : Rank 3: Sampled 20000 test rows from 1077950 total
2025-06-24 23:56:58 [INFO    ] [Rank-7028] numba.cuda.cudadrv.driver: init
2025-06-24 23:56:58 [INFO    ] [Rank-7031] numba.cuda.cudadrv.driver: init
2025-06-24 23:56:58 [INFO    ] [Rank-7029] root                : Rank 1: Sampled 20000 test rows from 1077950 total
2025-06-24 23:56:58 [INFO    ] [Rank-7029] numba.cuda.cudadrv.driver: init
2025-06-24 23:56:58 [INFO    ] [Rank-7030] root                : Total data: 4311800 train, 1077950 test rows
2025-06-24 23:56:58 [INFO    ] [Rank-7030] root                : Rank 2: Sampled 100000 train rows from 4311800 total
2025-06-24 23:56:58 [INFO    ] [Rank-7030] root                : Rank 2: Sampled 20000 test rows from 1077950 total
2025-06-24 23:56:58 [INFO    ] [Rank-7030] numba.cuda.cudadrv.driver: init
2025-06-24 23:56:59 [INFO    ] [Rank-7031] root                : Non-rank 0 process waiting for adaptive training to complete
2025-06-24 23:56:59 [INFO    ] [Rank-7029] root                : Non-rank 0 process waiting for adaptive training to complete
2025-06-24 23:56:59 [INFO    ] [Rank-7028] adaptive_trainer    : Starting adaptive training
2025-06-24 23:56:59 [INFO    ] [Rank-7028] adaptive_trainer    : 
=== Adaptive Training Iteration 1/20 ===
2025-06-24 23:56:59 [INFO    ] [Rank-7030] root                : Non-rank 0 process waiting for adaptive training to complete
2025-06-24 23:57:01 [INFO    ] [Rank-7028] adaptive_trainer    : Evaluation results: 17494 profits, total=nan
2025-06-24 23:57:01 [INFO    ] [Rank-7028] adaptive_trainer    : Metrics: CAGR=0.0000, Sharpe=-5.0000, MDD=100.0000
2025-06-24 23:57:01 [INFO    ] [Rank-7028] adaptive_trainer    : Current performance: -0.4500 (best: -0.4500)
2025-06-24 23:57:01 [INFO    ] [Rank-7028] adaptive_trainer    : Stagnation: 0, Poor performance: 0
2025-06-24 23:57:01 [INFO    ] [Rank-7028] adaptive_trainer    : Method: GA, Entropy: nan
2025-06-24 23:57:01 [INFO    ] [Rank-7028] adaptive_trainer    : Switching to PPO due to: ga_solution_refinement
2025-06-24 23:57:01 [INFO    ] [Rank-7028] adaptive_trainer    : Switching from GA to PPO
2025-06-24 23:57:01 [INFO    ] [Rank-7028] adaptive_trainer    : Starting PPO phase: 150 updates
2025-06-24 23:57:01 [INFO    ] [Rank-7028] policy_gradient_methods: No model file at models/4gpu_production/ppo_models/adaptive_ppo_model.pth, starting from scratch
[rank0]:I0624 23:57:01.965000 7028 site-packages/torch/distributed/nn/jit/instantiator.py:24] Created a temporary directory at /tmp/tmpdweyjsu5
[rank0]:I0624 23:57:01.966000 7028 site-packages/torch/distributed/nn/jit/instantiator.py:75] Writing /tmp/tmpdweyjsu5/_remote_module_non_scriptable.py
Removed old TensorBoard run: ./runs/ga_experiment
2025-06-24 23:57:03 [INFO    ] [Rank-7028] adaptive_trainer    : Evaluation results: 16696 profits, total=nan
2025-06-24 23:57:03 [INFO    ] [Rank-7028] adaptive_trainer    : Metrics: CAGR=0.0000, Sharpe=-5.0000, MDD=100.0000
2025-06-24 23:57:04 [WARNING ] [Rank-7028] adaptive_trainer    : PPO training step failed at update 0: Expected parameter logits (Tensor of shape (1, 3)) of distribution Categorical(logits: torch.Size([1, 3])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:
tensor([[nan, nan, nan]], device='cuda:0', grad_fn=<SubBackward0>)
2025-06-24 23:57:04 [INFO    ] [Rank-7028] policy_gradient_methods: Saved model to models/4gpu_production/ppo_models/adaptive_ppo_model.pth at 2025-06-24 23:57:04.032052
2025-06-24 23:57:04 [INFO    ] [Rank-7028] adaptive_trainer    : Evaluation results: 4291 profits, total=nan
2025-06-24 23:57:04 [INFO    ] [Rank-7028] adaptive_trainer    : Metrics: CAGR=0.0000, Sharpe=-5.0000, MDD=100.0000
2025-06-24 23:57:04 [INFO    ] [Rank-7028] adaptive_trainer    : PPO phase completed with performance: -0.4500
2025-06-24 23:57:04 [INFO    ] [Rank-7028] adaptive_trainer    : 
=== Adaptive Training Iteration 2/20 ===
2025-06-24 23:57:04 [INFO    ] [Rank-7028] adaptive_trainer    : Evaluation results: 6268 profits, total=nan
2025-06-24 23:57:04 [INFO    ] [Rank-7028] adaptive_trainer    : Metrics: CAGR=0.0000, Sharpe=-5.0000, MDD=100.0000
2025-06-24 23:57:04 [INFO    ] [Rank-7028] adaptive_trainer    : Current performance: -0.4500 (best: -0.4500)
2025-06-24 23:57:04 [INFO    ] [Rank-7028] adaptive_trainer    : Stagnation: 1, Poor performance: 1
2025-06-24 23:57:04 [INFO    ] [Rank-7028] adaptive_trainer    : Method: PPO, Entropy: nan
2025-06-24 23:57:04 [INFO    ] [Rank-7028] adaptive_trainer    : Switching to GA due to: exploration_phase
2025-06-24 23:57:04 [INFO    ] [Rank-7028] adaptive_trainer    : Switching from PPO to GA
2025-06-24 23:57:04 [INFO    ] [Rank-7028] adaptive_trainer    : Starting GA phase: 30 generations, population 30
[GA] No model file at models/4gpu_production/ga_models/adaptive_ga_model.pth, starting from scratch                                                                                                                        
[GA gens]:   0%|               