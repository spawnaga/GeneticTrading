/home/alex/miniconda3/envs/GeneticTrading/bin/python /mnt/windows/GeneticTrading/run_simple.py 
🤖 Trading System Launcher
==================================================
✓ Created directory: ./models
✓ Created directory: ./logs
✓ Created directory: ./cached_data
✓ Created directory: ./runs

Available modes:
  test - Quick test with minimal data (default)
  dev  - Development mode with 10% data

Usage: python run_simple.py [test|dev]

Select mode (test/dev) [test]: dev
🔧 Starting Development Mode...
📊 Using 10% of data for development
WARNING:root:Distributed training not available, running in single-process mode
2025-06-25 00:19:14 [INFO    ] [Rank-9953] STARTUP             : ================================================================================
2025-06-25 00:19:14 [INFO    ] [Rank-9953] STARTUP             : Training session started for rank 0
2025-06-25 00:19:14 [INFO    ] [Rank-9953] STARTUP             : Log file: logs/training_rank_0.log
2025-06-25 00:19:14 [INFO    ] [Rank-9953] STARTUP             : Process ID: 9953
2025-06-25 00:19:14 [INFO    ] [Rank-9953] STARTUP             : Working directory: /mnt/windows/GeneticTrading
2025-06-25 00:19:14 [INFO    ] [Rank-9953] STARTUP             : ================================================================================
2025-06-25 00:19:14 [INFO    ] [Rank-9953] root                : NCCL_TIMEOUT = 1800000 ms
2025-06-25 00:19:14 [INFO    ] [Rank-9953] root                : Using 10.0% of available data
2025-06-25 00:19:14 [INFO    ] [Rank-9953] root                : Models will be saved to: ./models/dev
2025-06-25 00:19:14 [INFO    ] [Rank-9953] root                : Rank 0/1 starting on cuda:0 (has_cudf=True)
2025-06-25 00:19:14 [INFO    ] [Rank-9953] root                : Parquet cache found; skipping preprocessing.
2025-06-25 00:19:14 [INFO    ] [Rank-9953] root                : Total data: 4311800 train, 1077950 test rows
2025-06-25 00:19:14 [INFO    ] [Rank-9953] root                : Rank 0: Sampled 100000 train rows from 4311800 total
2025-06-25 00:19:14 [INFO    ] [Rank-9953] root                : Rank 0: Sampled 20000 test rows from 1077950 total
2025-06-25 00:19:14 [INFO    ] [Rank-9953] numba.cuda.cudadrv.driver: init
2025-06-25 00:19:16 [INFO    ] [Rank-9953] adaptive_trainer    : Starting adaptive training
2025-06-25 00:19:16 [INFO    ] [Rank-9953] adaptive_trainer    : 
=== Adaptive Training Iteration 1/20 ===
2025-06-25 00:19:16 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
2025-06-25 00:19:19 [INFO    ] [Rank-9953] adaptive_trainer    : Evaluation results: 11857 profits, total=0.0000
2025-06-25 00:19:19 [INFO    ] [Rank-9953] adaptive_trainer    : Metrics: CAGR=0.0000, Sharpe=0.0000, MDD=100.0000
2025-06-25 00:19:19 [INFO    ] [Rank-9953] adaptive_trainer    : Current performance: -0.2000 (best: -0.2000)
2025-06-25 00:19:19 [INFO    ] [Rank-9953] adaptive_trainer    : Stagnation: 0, Poor performance: 0
2025-06-25 00:19:19 [INFO    ] [Rank-9953] adaptive_trainer    : Method: GA, Entropy: 1.0986
2025-06-25 00:19:19 [INFO    ] [Rank-9953] adaptive_trainer    : Switching to PPO due to: ga_solution_refinement
2025-06-25 00:19:19 [INFO    ] [Rank-9953] adaptive_trainer    : Switching from GA to PPO
2025-06-25 00:19:19 [INFO    ] [Rank-9953] adaptive_trainer    : Starting PPO phase: 150 updates
2025-06-25 00:19:19 [INFO    ] [Rank-9953] policy_gradient_methods: Loaded model from models/dev/ppo_models/adaptive_ppo_model.pth
I0625 00:19:19.291000 9953 site-packages/torch/distributed/nn/jit/instantiator.py:24] Created a temporary directory at /tmp/tmpw5_dcwxa
I0625 00:19:19.292000 9953 site-packages/torch/distributed/nn/jit/instantiator.py:75] Writing /tmp/tmpw5_dcwxa/_remote_module_non_scriptable.py
2025-06-25 00:19:19 [INFO    ] [Rank-9953] policy_gradient_methods: Loaded model from models/dev/ppo_models/adaptive_ppo_model.pth
2025-06-25 00:19:19 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
Removed old TensorBoard run: ./runs/ppo_rank_0
2025-06-25 00:19:22 [INFO    ] [Rank-9953] adaptive_trainer    : Evaluation results: 16308 profits, total=103517164.6051
2025-06-25 00:19:22 [INFO    ] [Rank-9953] adaptive_trainer    : Metrics: CAGR=249.8866, Sharpe=5.0000, MDD=0.0000
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:22 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.1762, value_loss=194655.3281, entropy=1.0900]
Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=0.1762, value_loss=194655.3281, entropy=1.0900]
Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=-0.0584, value_loss=201001.0312, entropy=1.0932]
Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=0.1297, value_loss=189275.7500, entropy=1.0926] 
Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=-0.0625, value_loss=150486.3438, entropy=1.0928]
Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=-0.0715, value_loss=183451.2812, entropy=1.0935]
Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=0.1614, value_loss=148310.5938, entropy=1.0931] 
Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=-0.1009, value_loss=232122.8438, entropy=1.0914]
Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=-0.0780, value_loss=192092.2500, entropy=1.0940]
Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=-0.0291, value_loss=189747.6094, entropy=1.0935]
Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=0.0770, value_loss=209086.8125, entropy=1.0926] 
Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=0.0115, value_loss=212280.1875, entropy=1.0931]2025-06-25 00:19:23 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros

Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=0.0374, value_loss=170514.5938, entropy=1.0905]
Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=-0.1499, value_loss=216886.2812, entropy=1.0937]
Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=-0.0020, value_loss=133995.4844, entropy=1.0898]
Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=-0.0108, value_loss=158158.5938, entropy=1.0944]
Epoch 1 Batches:   6%|▋         | 1/16 [00:00<00:02,  6.63it/s, policy_loss=-0.0264, value_loss=228293.7188, entropy=1.0941]
PPO Update Epochs:  25%|██▌       | 1/4 [00:00<00:00,  4.92it/s, avg_policy_loss=0.0002, avg_value_loss=188147.4189, kl_div=-0.0003]
Epoch 2 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
Epoch 2 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.1701, value_loss=283112.7500, entropy=1.0916]
Epoch 2 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.1244, value_loss=193291.6406, entropy=1.0941] 
Epoch 2 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.1426, value_loss=216585.6719, entropy=1.0941]2025-06-25 00:19:23 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros

Epoch 2 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.0903, value_loss=278911.4688, entropy=1.0942]
Epoch 2 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.1163, value_loss=153248.0938, entropy=1.0941]
Epoch 2 Batches:  31%|███▏      | 5/16 [00:00<00:00, 49.27it/s, policy_loss=-0.1163, value_loss=153248.0938, entropy=1.0941]
Epoch 2 Batches:  31%|███▏      | 5/16 [00:00<00:00, 49.27it/s, policy_loss=-0.0412, value_loss=167428.7812, entropy=1.0947]
Epoch 2 Batches:  31%|███▏      | 5/16 [00:00<00:00, 49.27it/s, policy_loss=-0.0817, value_loss=215848.7812, entropy=1.0926]
Epoch 2 Batches:  31%|███▏      | 5/16 [00:00<00:00, 49.27it/s, policy_loss=-0.0582, value_loss=186836.1406, entropy=1.0931]
Epoch 2 Batches:  31%|███▏      | 5/16 [00:00<00:00, 49.27it/s, policy_loss=0.0526, value_loss=160313.4844, entropy=1.0945] 
Epoch 2 Batches:  31%|███▏      | 5/16 [00:00<00:00, 49.27it/s, policy_loss=0.0811, value_loss=187286.6250, entropy=1.0929]
Epoch 2 Batches:  31%|███▏      | 5/16 [00:00<00:00, 49.27it/s, policy_loss=-0.0557, value_loss=162966.2188, entropy=1.0931]
Epoch 2 Batches:  31%|███▏      | 5/16 [00:00<00:00, 49.27it/s, policy_loss=0.1225, value_loss=167817.5312, entropy=1.0922] 
Epoch 2 Batches:  31%|███▏      | 5/16 [00:00<00:00, 49.27it/s, policy_loss=0.2613, value_loss=151735.3438, entropy=1.0939]
Epoch 2 Batches:  31%|███▏      | 5/16 [00:00<00:00, 49.27it/s, policy_loss=-0.0598, value_loss=175314.8125, entropy=1.0938]
Epoch 2 Batches:  31%|███▏      | 5/16 [00:00<00:00, 49.27it/s, policy_loss=0.0023, value_loss=139311.5000, entropy=1.0930] 
Epoch 2 Batches:  31%|███▏      | 5/16 [00:00<00:00, 49.27it/s, policy_loss=0.1782, value_loss=170251.4375, entropy=1.0909]
PPO Update Epochs:  50%|█████     | 2/4 [00:00<00:00,  5.91it/s, avg_policy_loss=0.0004, avg_value_loss=188141.2676, kl_div=-0.0004]
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.0557, value_loss=173103.8125, entropy=1.0952]2025-06-25 00:19:23 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros

Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.1180, value_loss=197000.6406, entropy=1.0935]
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.1803, value_loss=191696.0625, entropy=1.0957]
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.0797, value_loss=176453.5156, entropy=1.0951]
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.0163, value_loss=140900.4375, entropy=1.0908]
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.1025, value_loss=201770.1562, entropy=1.0931]
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.0719, value_loss=219817.2656, entropy=1.0928]
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.2294, value_loss=173581.2031, entropy=1.0928] 
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.0769, value_loss=180237.6250, entropy=1.0922]
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.1572, value_loss=193407.2500, entropy=1.0918]
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.0527, value_loss=217026.9375, entropy=1.0922]
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.1721, value_loss=137252.8750, entropy=1.0915] 
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.0608, value_loss=153647.7656, entropy=1.0924]
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.1053, value_loss=248226.5469, entropy=1.0919] 
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.1163, value_loss=189775.5938, entropy=1.0935]
Epoch 3 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.0866, value_loss=216282.7656, entropy=1.0893]
PPO Update Epochs:  50%|█████     | 2/4 [00:00<00:00,  5.91it/s, avg_policy_loss=0.0002, avg_value_loss=188136.2783, kl_div=-0.0004]
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.1909, value_loss=91814.8438, entropy=1.0894]
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.0116, value_loss=233013.2969, entropy=1.0939]
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.1834, value_loss=218174.7812, entropy=1.0917]
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.0473, value_loss=179502.1406, entropy=1.0898]
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.1640, value_loss=161081.3906, entropy=1.0943]
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.0664, value_loss=232471.9531, entropy=1.0956]
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.0100, value_loss=194297.6094, entropy=1.0904] 2025-06-25 00:19:23 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros

Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.0094, value_loss=208844.6250, entropy=1.0913]
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.0063, value_loss=225369.2031, entropy=1.0939]
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.2649, value_loss=232958.4375, entropy=1.0909]
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.0028, value_loss=192383.5000, entropy=1.0934] 
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.0859, value_loss=162820.7812, entropy=1.0950]
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.0838, value_loss=178588.2188, entropy=1.0956]
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.0875, value_loss=194954.6875, entropy=1.0927]
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=0.0408, value_loss=132961.3125, entropy=1.0921] 
Epoch 4 Batches:   0%|          | 0/16 [00:00<?, ?it/s, policy_loss=-0.0815, value_loss=170855.8281, entropy=1.0909]
Epoch 4 Batches: 100%|██████████| 16/16 [00:00<00:00, 142.25it/s, policy_loss=-0.0815, value_loss=170855.8281, entropy=1.0909]
2025-06-25 00:19:23 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
2025-06-25 00:19:23 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 0: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
2025-06-25 00:19:23 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:23 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:24 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 1: Parameter containing:
tensor([[-0.0004,  0.0011,  0.0016,  ...,  0.0003, -0.0002,  0.0017],
        [ 0.0004, -0.0012,  0.0016,  ...,  0.0003,  0.0009, -0.0014],
        [ 0.0005, -0.0018,  0.0006,  ..., -0.0014, -0.0007,  0.0012],
        ...,
        [-0.0004,  0.0001, -0.0003,  ..., -0.0018, -0.0003,  0.0009],
        [ 0.0018, -0.0008, -0.0012,  ...,  0.0006, -0.0017,  0.0005],
        [ 0.0006, -0.0005, -0.0003,  ..., -0.0014,  0.0004,  0.0016]],
       device='cuda:0', requires_grad=True)
2025-06-25 00:19:24 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:24 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:24 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 2: Parameter containing:
tensor([[ 1.7573e-03, -4.2602e-04,  5.5893e-04,  ..., -1.7504e-03,
         -6.4122e-04, -1.2378e-03],
        [-2.8225e-04, -1.7048e-03, -1.7466e-03,  ...,  1.7061e-03,
         -1.3164e-04,  5.6153e-04],
        [-4.0360e-04, -1.0607e-03,  6.6465e-04,  ..., -1.4765e-03,
         -1.3441e-03,  1.6909e-03],
        ...,
        [-1.0892e-03,  3.3683e-04, -8.1918e-05,  ..., -9.8961e-04,
         -1.0259e-03,  8.5200e-04],
        [ 2.0144e-04, -1.1856e-03, -8.1485e-04,  ...,  1.5903e-03,
          1.6681e-03,  1.0937e-03],
        [-7.8750e-04,  1.7597e-03,  1.5035e-03,  ...,  5.4590e-04,
         -1.2236e-03,  1.8171e-03]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:24 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:24 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:25 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 3: Parameter containing:
tensor([[-1.3928e-03, -1.0826e-03,  6.0948e-04,  ...,  1.3980e-03,
         -7.6082e-04, -7.1801e-04],
        [ 1.6113e-04,  9.5853e-04, -1.9180e-04,  ..., -1.3431e-03,
         -1.3720e-03,  1.2357e-03],
        [ 1.7196e-03,  1.6754e-03,  1.0600e-03,  ...,  1.1567e-03,
         -1.2035e-03,  4.4884e-04],
        ...,
        [-4.3860e-04,  1.5863e-03, -1.1767e-04,  ..., -5.1145e-04,
         -1.7949e-03,  1.5145e-03],
        [ 8.3645e-04, -1.4461e-03,  3.7861e-04,  ..., -7.5160e-04,
         -1.5762e-03, -2.6829e-04],
        [-1.2690e-03, -2.2396e-04,  1.6114e-03,  ...,  6.2561e-05,
          9.3319e-04,  1.6034e-03]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:25 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:25 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:26 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 4: Parameter containing:
tensor([[-1.2979e-03,  1.2161e-03, -1.2528e-03,  ...,  9.3952e-04,
         -1.5921e-03,  1.8149e-03],
        [-1.3214e-04,  8.9936e-04, -1.4379e-03,  ...,  4.8200e-04,
         -1.6550e-03, -5.9424e-04],
        [ 5.4764e-04,  1.1212e-03,  1.5391e-03,  ..., -1.3718e-04,
          9.6237e-04, -7.5328e-04],
        ...,
        [-5.7719e-04,  1.0449e-04,  4.3644e-04,  ...,  1.6651e-03,
          7.2824e-04, -1.1824e-04],
        [ 1.0044e-03,  3.3644e-04,  1.0316e-03,  ...,  1.9173e-04,
         -2.9556e-04, -1.5788e-03],
        [ 6.1745e-04,  1.2435e-03,  1.7616e-03,  ..., -7.8123e-05,
          5.0424e-04,  1.5379e-05]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:26 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:26 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:26 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 5: Parameter containing:
tensor([[-0.0010,  0.0012, -0.0015,  ...,  0.0007, -0.0006, -0.0004],
        [ 0.0009, -0.0007, -0.0007,  ...,  0.0015, -0.0007, -0.0008],
        [ 0.0017,  0.0017,  0.0007,  ...,  0.0004,  0.0007,  0.0018],
        ...,
        [ 0.0014,  0.0017,  0.0007,  ..., -0.0007, -0.0001,  0.0011],
        [ 0.0004,  0.0008,  0.0007,  ..., -0.0002,  0.0008, -0.0013],
        [ 0.0016,  0.0013,  0.0008,  ...,  0.0008,  0.0007,  0.0008]],
       device='cuda:0', requires_grad=True)
2025-06-25 00:19:26 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:26 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:27 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 6: Parameter containing:
tensor([[ 0.0006, -0.0012,  0.0008,  ..., -0.0011,  0.0011,  0.0016],
        [ 0.0007, -0.0009, -0.0006,  ..., -0.0010,  0.0003, -0.0018],
        [-0.0010,  0.0012, -0.0003,  ..., -0.0016, -0.0002, -0.0004],
        ...,
        [ 0.0004,  0.0008, -0.0007,  ...,  0.0002,  0.0012, -0.0010],
        [-0.0009, -0.0011, -0.0014,  ..., -0.0012,  0.0016, -0.0012],
        [ 0.0018,  0.0016,  0.0018,  ..., -0.0009,  0.0011,  0.0002]],
       device='cuda:0', requires_grad=True)
2025-06-25 00:19:27 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:27 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:27 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 7: Parameter containing:
tensor([[-0.0011,  0.0003, -0.0014,  ..., -0.0011,  0.0012, -0.0016],
        [-0.0007,  0.0005, -0.0002,  ..., -0.0010, -0.0006,  0.0002],
        [-0.0015,  0.0014,  0.0004,  ...,  0.0004,  0.0008, -0.0003],
        ...,
        [-0.0007,  0.0003, -0.0008,  ..., -0.0018,  0.0006,  0.0002],
        [-0.0002, -0.0004, -0.0012,  ...,  0.0012, -0.0010, -0.0015],
        [-0.0017,  0.0014, -0.0001,  ..., -0.0017, -0.0018,  0.0011]],
       device='cuda:0', requires_grad=True)
2025-06-25 00:19:27 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:27 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:28 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 8: Parameter containing:
tensor([[ 1.2337e-03,  8.2677e-04,  6.5941e-04,  ..., -2.7085e-04,
         -2.2424e-04,  1.7924e-03],
        [ 3.2934e-04,  8.4830e-04,  1.7423e-03,  ..., -4.6109e-04,
          6.9159e-04, -1.4033e-03],
        [-3.6645e-05, -5.8178e-04,  1.8568e-04,  ...,  4.8554e-04,
          1.2973e-04, -1.5613e-03],
        ...,
        [ 1.8009e-03, -1.4481e-03, -1.2464e-03,  ...,  3.8606e-04,
          1.8070e-03, -1.3265e-03],
        [-3.0747e-04,  6.1916e-04, -2.6929e-04,  ..., -1.5575e-03,
          9.1488e-04,  1.0026e-03],
        [-2.1838e-04,  1.0567e-03, -1.2710e-03,  ..., -1.1059e-03,
         -9.1476e-04, -7.8059e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:28 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:28 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:28 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 9: Parameter containing:
tensor([[-1.6188e-03, -2.5651e-05, -1.6236e-03,  ...,  1.0991e-03,
          1.6385e-03,  1.1286e-03],
        [-1.8168e-03,  1.0802e-03, -1.2942e-03,  ...,  1.9473e-04,
          1.8203e-03,  1.1396e-03],
        [ 9.5626e-04,  4.9808e-04, -4.3844e-04,  ..., -1.0431e-03,
         -1.3146e-03, -2.7178e-04],
        ...,
        [-1.0882e-03, -1.6860e-03, -1.1963e-03,  ..., -1.3662e-03,
         -1.0401e-03, -1.2486e-04],
        [ 6.3757e-04,  1.6883e-03,  1.2821e-03,  ...,  6.4749e-04,
         -1.5824e-03,  1.0373e-03],
        [ 9.9556e-04,  7.4557e-04, -2.2016e-04,  ...,  6.9991e-04,
         -2.0239e-04, -1.1941e-03]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:28 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:29 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 10: Parameter containing:
tensor([[ 1.2616e-03,  3.8199e-04,  6.8281e-04,  ...,  2.1248e-04,
          6.5645e-04,  4.8120e-04],
        [-1.4261e-03,  1.0622e-03, -1.1579e-03,  ...,  4.7677e-04,
          6.5595e-04, -1.5957e-03],
        [-8.2594e-04, -1.1387e-04,  1.0798e-03,  ..., -9.0862e-04,
         -6.5799e-04, -1.4989e-03],
        ...,
        [ 1.1400e-03,  3.8992e-04, -1.0799e-03,  ..., -5.4322e-04,
         -1.7237e-03, -9.4825e-04],
        [ 5.0856e-05, -1.5089e-03,  2.8680e-04,  ..., -1.1523e-03,
         -3.9887e-04,  5.2253e-05],
        [ 8.2699e-04, -1.6523e-03,  1.5364e-03,  ...,  1.3625e-03,
         -1.2139e-03, -1.7786e-03]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:29 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:29 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:29 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 11: Parameter containing:
tensor([[-7.5855e-04, -1.3022e-03,  7.2254e-06,  ..., -1.8034e-03,
         -2.1360e-04,  1.1590e-03],
        [-9.6747e-04, -7.6867e-04,  1.3392e-03,  ..., -1.4952e-03,
         -1.5807e-04,  1.5137e-03],
        [ 5.4285e-04,  4.7670e-04,  9.6043e-04,  ...,  1.4251e-03,
         -5.9845e-04,  6.1874e-04],
        ...,
        [ 1.8542e-04,  7.8621e-04, -1.7545e-03,  ..., -2.6960e-04,
          5.9811e-04, -1.2695e-03],
        [ 6.3030e-04, -1.0242e-03, -1.2584e-03,  ..., -3.8500e-04,
         -1.1623e-03,  1.4561e-03],
        [ 1.7883e-03,  1.3188e-03,  1.6482e-03,  ...,  9.8601e-04,
         -4.6307e-05, -1.6072e-03]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:29 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:29 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:30 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 12: Parameter containing:
tensor([[-0.0004, -0.0009, -0.0014,  ..., -0.0007, -0.0009,  0.0013],
        [-0.0003, -0.0012,  0.0010,  ...,  0.0016, -0.0018, -0.0014],
        [-0.0008, -0.0017, -0.0005,  ..., -0.0009,  0.0008,  0.0013],
        ...,
        [ 0.0004,  0.0007, -0.0016,  ...,  0.0006,  0.0003, -0.0010],
        [ 0.0008, -0.0007,  0.0016,  ...,  0.0006,  0.0009, -0.0018],
        [-0.0008, -0.0006,  0.0005,  ...,  0.0016,  0.0018,  0.0009]],
       device='cuda:0', requires_grad=True)
2025-06-25 00:19:30 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:30 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:30 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 13: Parameter containing:
tensor([[ 9.4371e-04,  1.4069e-03, -6.1293e-04,  ...,  8.4352e-04,
         -8.7188e-04,  3.3569e-04],
        [ 1.3302e-03, -9.0926e-04, -1.0001e-03,  ..., -2.4253e-04,
          1.4279e-05,  1.3785e-03],
        [ 4.0366e-04,  2.9536e-04,  5.3683e-04,  ...,  3.5796e-04,
         -1.7379e-03, -1.0016e-04],
        ...,
        [ 2.8548e-04,  1.0374e-03, -1.6031e-06,  ..., -4.8214e-04,
         -9.3075e-04,  7.3918e-04],
        [-6.0569e-04, -2.0739e-04, -2.0280e-04,  ...,  9.1488e-04,
         -3.2169e-04, -9.7841e-04],
        [-1.0949e-03, -6.4141e-04, -1.4575e-03,  ...,  1.5178e-03,
          1.5241e-04, -2.5173e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:30 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:30 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:31 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 14: Parameter containing:
tensor([[-9.3776e-04,  4.4750e-04, -6.7554e-04,  ..., -1.1387e-03,
          1.0377e-03,  1.3113e-03],
        [-1.3385e-03, -8.1245e-04, -6.4495e-04,  ...,  1.4032e-03,
          1.1788e-03, -1.1727e-03],
        [-3.5738e-04,  1.5395e-04, -1.4602e-03,  ..., -3.9178e-04,
         -6.5761e-04, -1.3080e-03],
        ...,
        [ 1.1781e-03, -1.4713e-03,  1.5864e-03,  ...,  7.0749e-04,
          1.1354e-03, -1.0861e-03],
        [ 1.3546e-03, -4.6540e-05,  1.6033e-03,  ..., -9.8949e-04,
         -1.0650e-03,  6.0094e-04],
        [-4.7286e-04, -3.4717e-05, -1.3954e-03,  ...,  1.5199e-03,
          1.7619e-03,  3.3132e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:31 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:31 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 15: Parameter containing:
tensor([[-9.7180e-04, -1.8009e-03,  4.0571e-04,  ...,  9.7455e-04,
         -8.3939e-04,  1.5457e-03],
        [-1.5745e-03, -1.0715e-03,  1.7821e-03,  ..., -1.0352e-03,
          1.8216e-04, -1.4760e-03],
        [ 1.1761e-03, -6.2016e-04,  1.1909e-03,  ..., -8.3777e-04,
          6.7861e-05,  8.5740e-04],
        ...,
        [ 1.7858e-03,  1.6426e-03,  1.4609e-04,  ...,  1.1972e-03,
          1.2573e-03, -1.2468e-03],
        [-1.7839e-03,  8.2469e-04,  4.0820e-04,  ...,  8.6558e-04,
          1.1305e-04,  2.7139e-04],
        [ 1.3157e-03, -1.5582e-03,  1.6460e-03,  ..., -1.3316e-03,
         -9.4850e-04, -2.9051e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:31 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:31 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:32 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 16: Parameter containing:
tensor([[ 1.7953e-03,  1.1580e-03, -7.7031e-04,  ..., -2.4767e-04,
         -1.3545e-04,  1.3247e-03],
        [ 5.1758e-04, -4.1549e-04,  3.9137e-04,  ...,  1.0815e-03,
         -5.5663e-04, -7.5402e-04],
        [ 5.5830e-04, -2.5274e-04,  7.5329e-04,  ..., -6.5690e-04,
          1.0846e-03, -8.2795e-04],
        ...,
        [ 1.3706e-03, -1.8134e-03, -1.2374e-04,  ..., -1.4228e-04,
         -2.4113e-04, -1.1749e-03],
        [-5.0391e-04,  3.9020e-06,  2.9621e-04,  ...,  1.2579e-03,
         -4.2150e-04, -5.5074e-05],
        [ 2.6132e-04,  7.5848e-04,  1.7587e-03,  ...,  1.3623e-03,
          1.1303e-03,  4.8762e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:32 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:32 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]2025-06-25 00:19:32 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros

2025-06-25 00:19:32 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 17: Parameter containing:
tensor([[-0.0004,  0.0014,  0.0005,  ..., -0.0009,  0.0006,  0.0008],
        [-0.0002,  0.0010, -0.0006,  ...,  0.0016,  0.0014,  0.0005],
        [ 0.0017,  0.0015, -0.0008,  ..., -0.0004,  0.0015,  0.0010],
        ...,
        [ 0.0012, -0.0001,  0.0013,  ...,  0.0003,  0.0012, -0.0007],
        [-0.0017,  0.0003,  0.0004,  ..., -0.0017, -0.0010,  0.0004],
        [ 0.0013, -0.0009, -0.0017,  ...,  0.0008,  0.0005, -0.0011]],
       device='cuda:0', requires_grad=True)
2025-06-25 00:19:32 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:32 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:33 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 18: Parameter containing:
tensor([[ 1.0862e-04, -6.2114e-04, -2.3261e-04,  ...,  1.5130e-03,
          3.6315e-04, -1.3687e-04],
        [-1.2438e-03,  1.4067e-03, -1.3557e-03,  ...,  1.1637e-03,
          1.5859e-03, -3.1189e-04],
        [ 1.3400e-03,  1.8074e-03,  6.5509e-04,  ...,  1.7222e-03,
          1.0745e-04,  1.4139e-03],
        ...,
        [-1.8134e-03,  1.4282e-04, -1.7765e-03,  ...,  5.8050e-05,
         -1.0823e-03,  1.3154e-03],
        [-8.3136e-04, -1.5245e-03, -1.2347e-03,  ..., -1.3113e-03,
          4.3341e-04,  1.4200e-03],
        [ 1.9541e-04,  1.3682e-03,  8.2183e-04,  ...,  6.4529e-04,
         -1.0500e-04, -1.0609e-03]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:33 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:33 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:33 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 19: Parameter containing:
tensor([[ 1.2606e-03,  6.4447e-04,  9.1620e-04,  ..., -1.2825e-03,
          7.4862e-04,  5.7287e-04],
        [ 1.2522e-03,  9.1470e-04,  1.3425e-04,  ..., -1.3785e-03,
          1.3515e-03, -1.3705e-03],
        [ 1.1014e-03, -1.2559e-03,  1.2799e-03,  ...,  3.2239e-04,
         -2.0378e-04, -1.6000e-03],
        ...,
        [-1.3381e-03, -1.3122e-03,  6.7249e-04,  ..., -1.0800e-03,
          7.7162e-04, -1.0477e-03],
        [ 1.2376e-03, -1.1590e-03, -1.1939e-03,  ...,  4.5493e-04,
         -2.0137e-05,  5.7033e-04],
        [ 1.6858e-03,  1.4850e-03,  1.2557e-03,  ...,  2.3719e-04,
         -9.3394e-04, -3.2657e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:33 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:33 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:34 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 20: Parameter containing:
tensor([[ 1.0800e-03,  5.5428e-05,  6.1339e-05,  ..., -7.6972e-04,
          1.0600e-03,  5.2702e-04],
        [-1.2471e-03,  4.2119e-04, -8.5489e-04,  ..., -3.0450e-04,
         -1.4135e-03, -1.7213e-03],
        [-7.6198e-04, -5.2322e-04,  1.3396e-03,  ...,  1.2992e-03,
         -5.7748e-04,  1.2567e-03],
        ...,
        [ 1.7581e-03,  7.6189e-04, -3.3512e-04,  ...,  7.6134e-04,
         -6.5838e-05, -1.6370e-04],
        [ 1.0312e-03,  7.1333e-04, -1.4153e-03,  ...,  1.4676e-03,
          9.4607e-04, -1.1264e-03],
        [-1.2781e-03,  4.3441e-04, -1.8896e-04,  ...,  1.2092e-03,
         -7.6264e-04,  2.4118e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:34 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:34 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:34 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 21: Parameter containing:
tensor([[ 1.7204e-03,  1.2767e-03,  1.0755e-03,  ..., -1.1830e-03,
          2.2927e-04, -1.0782e-03],
        [ 2.0768e-04,  1.6803e-03,  1.5605e-04,  ..., -1.7439e-03,
         -3.2854e-04, -5.2770e-04],
        [ 8.8551e-04,  8.6765e-04,  1.5179e-03,  ..., -8.0683e-04,
         -1.3934e-03, -5.2977e-05],
        ...,
        [ 9.0590e-04,  1.4948e-03, -2.3051e-04,  ...,  8.6578e-04,
         -6.1161e-05, -1.1552e-04],
        [-1.5719e-03, -4.8696e-04, -1.4734e-03,  ..., -6.1793e-04,
         -1.1150e-04, -9.5604e-04],
        [-1.0858e-03,  9.3458e-04, -1.2712e-03,  ...,  3.8886e-04,
          6.0448e-04, -4.8217e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:34 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:34 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:35 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 22: Parameter containing:
tensor([[-1.3269e-03,  8.7070e-04, -1.5552e-03,  ..., -8.7349e-04,
          1.4868e-03,  5.7655e-04],
        [ 9.4643e-04,  1.4878e-03, -1.5823e-03,  ..., -4.4352e-04,
         -3.6173e-05, -1.2543e-03],
        [ 1.2596e-03, -7.9149e-04, -1.2279e-03,  ..., -1.3373e-03,
         -1.2834e-03,  2.4951e-04],
        ...,
        [ 1.6454e-03,  1.3110e-03,  1.5433e-03,  ...,  1.0314e-03,
          1.6870e-04, -7.8620e-05],
        [ 3.8080e-04,  1.0225e-03, -2.2503e-04,  ..., -1.4324e-03,
          8.4740e-04, -1.6708e-03],
        [ 1.2531e-03,  7.3736e-04,  4.5648e-04,  ...,  1.2817e-03,
          1.4566e-03, -1.7953e-03]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:35 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:35 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:35 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 23: Parameter containing:
tensor([[-7.1448e-04,  1.3258e-04,  5.1874e-04,  ..., -1.8185e-03,
         -1.5385e-03,  1.4097e-03],
        [ 1.6040e-03,  1.7155e-05, -7.3717e-05,  ..., -3.9276e-04,
         -1.2369e-03,  1.0448e-03],
        [ 1.2650e-03,  1.2877e-03,  8.1512e-04,  ...,  1.6591e-03,
          1.1204e-03,  1.7401e-03],
        ...,
        [-2.5741e-05, -3.7430e-04,  1.4020e-03,  ...,  1.4908e-03,
         -2.3183e-04,  1.3785e-03],
        [ 1.4791e-03,  4.9701e-04, -1.3525e-03,  ..., -1.1019e-03,
         -4.5363e-04,  3.7683e-04],
        [ 1.5966e-03,  9.2636e-04, -8.5859e-04,  ...,  1.6427e-03,
         -4.6246e-04,  2.5646e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:35 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:35 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:36 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 24: Parameter containing:
tensor([[-8.6691e-04, -1.4216e-03, -2.5449e-04,  ...,  7.6713e-04,
          3.1388e-04,  7.3293e-04],
        [-6.0499e-04,  3.7567e-04, -4.9185e-05,  ...,  7.5335e-04,
          1.6041e-03,  1.4204e-03],
        [ 6.1434e-04, -1.4582e-03, -1.0134e-03,  ...,  7.3635e-04,
          1.6713e-03,  1.3805e-03],
        ...,
        [-1.1160e-04, -3.2852e-04, -1.5844e-03,  ...,  3.1956e-04,
          5.2307e-04, -1.0060e-03],
        [ 1.1553e-03,  1.0436e-03, -6.5271e-04,  ..., -3.2174e-04,
          1.4825e-03,  9.5144e-04],
        [-3.1669e-04,  1.3435e-03, -1.1754e-03,  ..., -6.0867e-04,
         -8.1686e-04, -8.4732e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:36 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:36 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:36 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 25: Parameter containing:
tensor([[-1.2540e-04, -3.8873e-04,  1.1328e-03,  ...,  8.3917e-04,
         -2.2677e-04, -1.1929e-03],
        [-1.5615e-03,  1.1590e-03, -1.7925e-03,  ..., -8.3262e-05,
         -7.5719e-04,  1.5542e-03],
        [-4.0937e-04, -6.2394e-04,  1.2410e-03,  ..., -8.1801e-04,
          1.2786e-03, -1.4630e-03],
        ...,
        [ 1.2187e-03,  1.6438e-03,  8.4092e-04,  ...,  4.1229e-04,
         -1.7980e-03, -1.6783e-03],
        [-3.1188e-04, -1.5360e-03, -1.3686e-03,  ...,  2.1495e-04,
         -1.7720e-03, -5.0117e-04],
        [-1.1761e-03, -1.4067e-03,  4.5474e-05,  ...,  1.3368e-03,
         -9.7693e-04, -1.7260e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:36 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:36 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:37 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 26: Parameter containing:
tensor([[-6.3935e-04, -5.5935e-04, -8.6956e-05,  ..., -1.3537e-03,
          1.5679e-03,  4.3982e-05],
        [ 1.1588e-05,  3.7746e-04, -3.6464e-04,  ...,  2.1691e-04,
          1.4642e-03,  1.3746e-03],
        [ 3.1455e-04, -1.5313e-03,  4.6829e-04,  ...,  1.6860e-03,
          1.3767e-03, -8.2666e-04],
        ...,
        [-3.3071e-04, -7.3022e-04,  1.4661e-03,  ..., -1.4765e-03,
          6.3001e-04,  1.2216e-03],
        [-1.4508e-04,  3.0745e-04, -1.3163e-03,  ..., -1.2810e-03,
         -4.4480e-04, -4.8301e-05],
        [-8.8740e-04,  4.7368e-04, -4.6661e-04,  ...,  4.1682e-05,
          1.6193e-03,  2.4464e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:37 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:37 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:37 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 27: Parameter containing:
tensor([[ 1.6566e-03, -1.4464e-03, -3.5774e-05,  ..., -5.3555e-04,
         -4.1284e-04,  1.5297e-03],
        [ 1.6475e-03, -1.7335e-03,  1.3689e-03,  ..., -1.3133e-03,
          4.5901e-04, -1.7016e-03],
        [-1.4590e-03,  9.4695e-04,  1.4608e-04,  ..., -7.8638e-04,
         -9.4649e-04, -4.1129e-04],
        ...,
        [ 1.1593e-03, -5.3288e-04,  6.2167e-04,  ...,  5.1854e-04,
          4.8938e-04, -3.0896e-04],
        [-1.3680e-03,  2.9413e-04, -1.1729e-04,  ...,  6.9539e-04,
          1.0690e-03, -1.5692e-04],
        [ 1.3099e-03, -1.0143e-03,  8.7021e-05,  ..., -2.2538e-05,
          1.4467e-03, -9.7440e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:37 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:37 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:38 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 28: Parameter containing:
tensor([[ 1.4690e-03,  9.0175e-05, -6.9120e-04,  ..., -1.8110e-03,
          1.5225e-03,  8.9624e-04],
        [ 4.6905e-04, -9.3413e-04,  1.1557e-03,  ..., -1.5364e-03,
          7.8156e-04, -1.1366e-03],
        [-1.7030e-04, -5.6025e-04,  8.5248e-04,  ...,  1.4999e-03,
          8.3457e-04, -6.3157e-04],
        ...,
        [ 1.6694e-03,  1.4735e-03,  1.5242e-03,  ...,  1.3881e-03,
          1.1984e-03, -3.7092e-04],
        [ 1.1983e-03, -1.6541e-04, -8.6630e-04,  ...,  8.1126e-04,
         -9.4643e-04, -1.8923e-04],
        [ 1.3978e-03, -1.4212e-03,  1.7822e-03,  ...,  5.9409e-04,
         -1.6716e-03,  9.0804e-05]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:38 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:38 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:38 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 29: Parameter containing:
tensor([[-0.0012,  0.0004,  0.0009,  ...,  0.0003, -0.0017,  0.0010],
        [-0.0018,  0.0007, -0.0014,  ...,  0.0010, -0.0009, -0.0002],
        [-0.0017,  0.0002,  0.0012,  ..., -0.0012,  0.0007, -0.0008],
        ...,
        [-0.0016, -0.0013,  0.0013,  ..., -0.0014,  0.0005, -0.0018],
        [-0.0002,  0.0009, -0.0001,  ..., -0.0017,  0.0009, -0.0003],
        [-0.0006,  0.0015, -0.0011,  ..., -0.0002,  0.0009, -0.0005]],
       device='cuda:0', requires_grad=True)
2025-06-25 00:19:38 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:38 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:39 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 30: Parameter containing:
tensor([[-1.5725e-03,  9.3390e-04, -1.0314e-03,  ...,  2.4765e-04,
          7.0116e-04, -1.2583e-03],
        [-1.6092e-03,  3.2570e-04,  6.6863e-05,  ..., -6.1671e-04,
          1.6029e-03,  7.7951e-04],
        [-1.1188e-04,  1.3402e-03,  1.4423e-03,  ..., -5.7783e-04,
         -1.7006e-03, -6.0759e-04],
        ...,
        [-7.2388e-04,  9.7800e-04,  3.2779e-04,  ...,  7.3920e-04,
         -1.2145e-04, -8.8155e-04],
        [ 1.1239e-03,  1.7527e-03,  9.2428e-04,  ...,  8.7910e-04,
         -1.6217e-04, -7.4919e-04],
        [ 1.0109e-03, -1.0058e-03, -1.5360e-04,  ...,  6.6376e-04,
          1.9861e-04,  4.0151e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:39 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:39 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:39 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 31: Parameter containing:
tensor([[-1.3524e-03, -1.1341e-03, -1.7372e-03,  ..., -1.1238e-03,
         -1.0157e-03,  9.8741e-04],
        [ 1.4668e-03,  2.4467e-04,  5.8889e-04,  ...,  7.5949e-04,
          6.9394e-04,  1.3198e-03],
        [-1.2172e-03, -1.4493e-03, -4.1793e-04,  ...,  2.5964e-04,
         -1.6458e-04,  1.0782e-03],
        ...,
        [ 9.1482e-05, -8.4526e-04, -1.5211e-03,  ...,  8.5768e-04,
          3.6224e-04, -1.7360e-03],
        [ 2.1546e-04,  9.2933e-04,  1.1757e-03,  ...,  1.3257e-03,
         -1.5338e-03, -6.7839e-04],
        [-1.2400e-03, -1.5387e-03, -1.1893e-03,  ...,  9.3512e-04,
         -1.6372e-03, -1.4699e-03]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:39 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:40 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 32: Parameter containing:
tensor([[ 1.1763e-03, -9.4481e-04,  1.4046e-03,  ...,  1.1848e-03,
         -3.3996e-04,  8.9272e-06],
        [ 1.3309e-04, -9.7598e-04,  5.2987e-04,  ...,  1.6309e-03,
          1.1267e-03, -1.5975e-03],
        [-5.1317e-04,  8.1204e-04,  8.6583e-04,  ..., -1.0805e-03,
         -1.2882e-03,  4.6842e-04],
        ...,
        [-1.4202e-03,  2.3489e-04, -7.5748e-04,  ..., -1.0321e-03,
          3.8094e-04,  7.1642e-05],
        [ 1.5712e-03, -9.6937e-04, -5.0334e-04,  ..., -1.3961e-03,
         -1.7228e-03, -1.7224e-03],
        [ 6.6022e-04,  7.5826e-04, -2.5974e-04,  ..., -8.3568e-04,
         -1.0071e-03,  9.5395e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:40 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:40 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 33: Parameter containing:
tensor([[-1.5446e-03,  1.7019e-03, -4.5071e-04,  ...,  1.6436e-03,
         -1.9974e-04, -8.4407e-05],
        [ 1.7538e-03,  1.4421e-03,  1.0225e-03,  ...,  1.2195e-03,
         -1.7331e-03, -1.2324e-03],
        [ 7.3683e-04,  1.5908e-03,  1.1002e-03,  ..., -1.3123e-03,
          3.9376e-04, -1.4987e-03],
        ...,
        [-1.6454e-03, -1.1691e-04,  4.3796e-04,  ..., -3.0787e-04,
         -9.0787e-04,  1.1339e-03],
        [-1.0633e-03,  9.7021e-04, -1.6580e-03,  ..., -1.2122e-03,
          2.1773e-04, -6.0161e-04],
        [-6.3793e-04,  1.0986e-03, -1.2656e-04,  ...,  1.2994e-03,
         -9.7886e-04, -9.9304e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:40 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:40 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:41 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 34: Parameter containing:
tensor([[ 1.1654e-03, -1.5842e-03,  9.1241e-04,  ...,  4.3200e-04,
          1.4449e-03,  7.7596e-04],
        [ 8.4010e-04, -1.4421e-03,  7.0779e-04,  ...,  2.4328e-04,
         -3.1177e-04, -2.2021e-04],
        [-1.7392e-03,  1.5255e-03,  7.8184e-04,  ...,  1.7253e-03,
          1.1343e-03,  8.8876e-04],
        ...,
        [-2.8280e-05,  1.4320e-03, -7.4385e-04,  ..., -2.5416e-05,
          1.1956e-03, -7.4291e-04],
        [ 9.6050e-04,  1.5199e-04,  1.5746e-03,  ...,  1.6908e-03,
          9.9166e-04,  1.5461e-04],
        [ 1.5394e-03,  1.0649e-04,  1.4411e-03,  ..., -1.6564e-03,
         -4.7161e-04,  3.8593e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:41 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:41 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]2025-06-25 00:19:41 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros

2025-06-25 00:19:41 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 35: Parameter containing:
tensor([[ 2.2076e-04,  1.6281e-03,  4.6667e-05,  ..., -1.2174e-03,
          7.3824e-04, -1.4213e-03],
        [-1.3676e-03,  1.1345e-03, -1.6748e-03,  ...,  1.3948e-03,
          9.4391e-04, -1.4949e-03],
        [-1.0631e-03,  9.2473e-04,  6.5895e-04,  ...,  1.8252e-04,
          5.6873e-05,  8.2872e-04],
        ...,
        [-1.3986e-03,  1.2812e-03, -6.7016e-04,  ...,  1.5240e-03,
          3.2345e-04,  1.2088e-03],
        [-3.9433e-04, -1.0554e-03,  9.1695e-04,  ...,  4.6583e-04,
          1.6804e-03,  1.0305e-03],
        [-1.9182e-04,  1.0877e-03,  4.6649e-04,  ..., -9.4737e-04,
         -7.2636e-04,  8.7775e-05]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:41 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:41 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:42 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 36: Parameter containing:
tensor([[-9.2135e-04,  1.1941e-03, -8.3772e-04,  ...,  1.1427e-03,
          1.2246e-03,  2.8095e-04],
        [ 8.4767e-04,  1.2021e-03, -2.5371e-04,  ...,  6.8678e-04,
          1.7901e-03, -2.5268e-04],
        [-1.0459e-03, -1.1730e-03, -1.1124e-03,  ..., -9.9986e-04,
          2.7068e-04,  1.6329e-05],
        ...,
        [-1.6350e-03,  4.9829e-04, -1.6076e-03,  ..., -5.2374e-04,
          3.3707e-04, -5.0348e-04],
        [-2.7919e-04, -1.5442e-03, -1.4085e-03,  ..., -8.1064e-04,
          1.1349e-03,  1.5486e-03],
        [ 4.4573e-04,  1.2464e-03,  6.7294e-04,  ..., -4.3430e-04,
          5.0205e-05,  1.0664e-03]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:42 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:42 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:42 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 37: Parameter containing:
tensor([[ 6.0738e-04,  6.9259e-04,  4.6154e-04,  ...,  1.1480e-03,
         -8.6550e-04, -7.7218e-04],
        [-1.0704e-03, -6.2186e-04,  7.1698e-04,  ...,  1.7544e-03,
          7.1474e-04, -1.0203e-03],
        [ 1.7513e-03,  1.0391e-03, -1.7170e-03,  ..., -1.8446e-04,
          5.1570e-04, -1.3269e-03],
        ...,
        [-1.5707e-03, -1.3150e-03, -9.8605e-04,  ...,  4.4229e-04,
          1.2531e-03,  1.3912e-03],
        [ 1.4579e-04,  1.5775e-03,  9.5196e-04,  ..., -1.0102e-03,
          5.7326e-05, -1.2665e-03],
        [ 1.3356e-03, -4.9746e-04, -4.1011e-04,  ..., -1.3295e-03,
          1.4337e-03,  1.7450e-03]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:42 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:42 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:43 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 38: Parameter containing:
tensor([[-1.5603e-03,  1.3261e-03, -1.8001e-03,  ..., -4.1913e-04,
         -9.1566e-04,  3.8722e-04],
        [ 1.4209e-03,  1.7903e-03, -4.1109e-04,  ..., -1.3625e-03,
         -1.2728e-03, -1.7176e-04],
        [ 1.1310e-03, -6.4034e-04,  1.0077e-03,  ..., -1.1851e-03,
          1.7105e-03,  1.5165e-03],
        ...,
        [ 1.1664e-03,  2.4936e-04,  1.6493e-03,  ...,  2.8336e-04,
          7.4777e-04, -1.8061e-03],
        [-1.5196e-03, -1.2128e-03, -1.3444e-03,  ...,  6.4756e-05,
          7.8009e-05, -1.3886e-05],
        [-7.6802e-04,  1.7898e-03, -1.7424e-03,  ...,  1.1392e-03,
         -5.3515e-04, -6.4727e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:43 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:43 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:44 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 39: Parameter containing:
tensor([[-1.0723e-03,  1.3722e-03, -1.0211e-03,  ...,  1.7973e-03,
         -1.3264e-03, -1.0341e-03],
        [ 1.0812e-03, -9.1719e-04, -4.9188e-04,  ..., -2.8323e-04,
         -8.0498e-04,  1.5239e-03],
        [ 1.1941e-03,  1.3041e-03,  1.2194e-03,  ...,  1.6955e-03,
         -1.1747e-03, -5.9503e-04],
        ...,
        [-3.9946e-04,  1.5145e-03, -4.1322e-04,  ..., -8.5143e-04,
         -1.2109e-03, -5.9568e-05],
        [ 1.0116e-04, -1.0562e-03,  1.4998e-03,  ..., -1.6956e-03,
          5.9426e-04,  1.0417e-03],
        [ 1.0216e-03,  1.1410e-03,  2.0575e-04,  ..., -4.5778e-04,
         -4.0567e-04, -4.8456e-05]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:44 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:44 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]2025-06-25 00:19:44 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros

2025-06-25 00:19:44 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 40: Parameter containing:
tensor([[-1.0333e-03, -1.3130e-03,  1.4372e-03,  ..., -4.4757e-04,
         -9.1426e-04, -2.0582e-04],
        [ 5.3308e-04, -1.7446e-03, -1.1753e-03,  ..., -1.0653e-03,
          1.0777e-03,  8.6682e-04],
        [ 1.7860e-03,  1.7833e-03, -9.6963e-04,  ...,  1.3249e-03,
         -1.0665e-03, -1.5655e-03],
        ...,
        [ 1.1805e-04, -1.0281e-03, -1.7450e-03,  ..., -4.2570e-04,
          9.7350e-04, -1.5332e-03],
        [-6.3198e-04, -1.3597e-04,  1.4417e-03,  ...,  1.1020e-03,
          1.1854e-03,  1.5985e-03],
        [ 9.3014e-04, -1.4230e-03, -1.3326e-03,  ..., -3.3812e-04,
         -1.9849e-05,  7.1369e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:44 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:44 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]2025-06-25 00:19:45 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros

2025-06-25 00:19:45 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 41: Parameter containing:
tensor([[-1.2887e-03, -1.2685e-03,  1.3830e-04,  ..., -4.4641e-04,
         -1.6307e-03, -6.3566e-04],
        [ 5.9635e-04, -1.3586e-03,  6.3995e-04,  ..., -7.2656e-05,
          2.4390e-04, -1.3347e-03],
        [ 1.1002e-03,  1.0382e-03, -1.1088e-03,  ...,  1.7805e-03,
          9.4230e-04,  1.3093e-03],
        ...,
        [ 4.7249e-04,  1.1093e-03, -1.0273e-03,  ..., -1.2603e-03,
          1.0078e-04,  1.1976e-03],
        [ 1.0737e-03, -1.3949e-03, -1.4395e-03,  ...,  8.2212e-04,
          8.8612e-05,  7.4606e-04],
        [ 5.0525e-04,  1.1193e-04,  2.2535e-04,  ..., -6.3436e-04,
         -9.1013e-05,  1.6996e-03]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:45 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:45 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 42: Parameter containing:
tensor([[-2.4270e-04,  8.9751e-04,  1.6458e-03,  ...,  1.3099e-03,
         -1.2945e-03,  1.3487e-03],
        [ 1.7732e-03,  1.6342e-03, -3.9948e-05,  ...,  1.7720e-03,
         -1.2570e-03,  9.7624e-04],
        [ 1.1327e-03,  9.5673e-04,  7.7863e-04,  ..., -1.4249e-04,
          1.1244e-03,  1.6701e-04],
        ...,
        [-5.3233e-04,  2.5643e-05,  6.6033e-04,  ...,  4.9739e-05,
          1.0262e-03, -5.7999e-04],
        [ 1.8011e-04,  8.3001e-04,  1.0129e-03,  ...,  1.2533e-03,
          3.4366e-04, -9.4591e-04],
        [-1.0472e-03, -1.6396e-03, -2.6092e-04,  ...,  1.5273e-03,
         -1.2021e-05, -7.4470e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:45 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:45 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:46 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 43: Parameter containing:
tensor([[ 1.4912e-03, -1.3459e-03,  2.1234e-04,  ..., -2.2748e-04,
         -4.9554e-04, -1.2884e-03],
        [ 4.2694e-04,  1.3772e-03,  1.2156e-03,  ...,  8.4730e-04,
          4.6950e-05,  5.0658e-04],
        [-1.3080e-03, -8.5169e-04, -9.5747e-04,  ...,  1.0050e-03,
         -1.1299e-03, -4.7200e-04],
        ...,
        [-9.2725e-05,  3.1433e-04, -1.2172e-03,  ..., -1.4965e-03,
          6.9498e-04, -1.4605e-03],
        [ 1.4774e-04, -1.2513e-03, -6.2537e-04,  ...,  1.4378e-03,
         -2.8842e-04,  1.3575e-03],
        [-2.7037e-06,  1.0326e-03, -3.0374e-04,  ..., -1.4082e-03,
         -9.0155e-04,  1.7123e-03]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:46 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:46 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
PPO Update Epochs:   0%|          | 0/4 [00:00<?, ?it/s]
Epoch 1 Batches:   0%|          | 0/16 [00:00<?, ?it/s]
2025-06-25 00:19:46 [WARNING ] [Rank-9953] adaptive_trainer    : PPO training step failed at update 44: Parameter containing:
tensor([[-1.6981e-03,  2.9921e-04, -3.8514e-04,  ...,  1.1923e-03,
          2.7558e-04, -5.3239e-04],
        [ 8.1388e-04, -6.7978e-04,  1.6478e-03,  ...,  1.2934e-03,
         -1.0968e-04, -1.6837e-03],
        [-9.6122e-04,  9.9678e-05, -6.8013e-04,  ..., -6.6967e-04,
         -1.1544e-03, -5.3239e-04],
        ...,
        [ 6.9261e-04, -1.4782e-03, -1.2669e-03,  ...,  1.5321e-03,
          8.0763e-04, -1.3990e-03],
        [-1.1301e-03,  1.5710e-03,  7.3976e-04,  ..., -4.8968e-04,
          5.0617e-04,  2.9275e-04],
        [ 1.2768e-03,  5.0823e-04,  1.5406e-03,  ...,  7.7764e-04,
         -6.6236e-04,  3.9365e-04]], device='cuda:0', requires_grad=True)
2025-06-25 00:19:46 [INFO    ] [Rank-9953] adaptive_trainer    : Attempting to recover by reinitializing PPO model
Collecting trajectories:   0%|          | 0/1024 [00:00<?, ?it/s]2025-06-25 00:19:46 [WARNING ] [Rank-9953] policy_gradient_methods: NaN/infinite input detected, replacing with zeros
